{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33efc22",
   "metadata": {
    "papermill": {
     "duration": 0.005426,
     "end_time": "2025-01-10T10:23:13.440334",
     "exception": false,
     "start_time": "2025-01-10T10:23:13.434908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Additional\n",
    "\n",
    "- 2024/12/24 : find weights ensemble and add in predict() preds = (w) * preds_xgb + (w-1) * preds_nn\n",
    "- 2024/12/26 : XGB local train modelx5 add. dataset is here\n",
    "    - https://www.kaggle.com/code/hideyukizushi/js-nnx5-xgbx6-weighted-blend-lb-0-0077\n",
    "- 2025/01/02 : add weights ensemble of public notebook\n",
    "    - https://www.kaggle.com/code/yunsuxiaozi/js-ridge-baseline?scriptVersionId=202739388\n",
    "    - https://www.kaggle.com/code/hideyukizushi/js-nnx5-xgbx5-weighted-blend-lb-0-0078/notebook?scriptVersionId=215419804\n",
    "    - https://www.kaggle.com/code/i2nfinit3y/jane-street-tabm-ft-transformer-inference?scriptVersionId=213715783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26839826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:13.452005Z",
     "iopub.status.busy": "2025-01-10T10:23:13.451290Z",
     "iopub.status.idle": "2025-01-10T10:23:22.842183Z",
     "shell.execute_reply": "2025-01-10T10:23:22.841020Z"
    },
    "papermill": {
     "duration": 9.399496,
     "end_time": "2025-01-10T10:23:22.844771",
     "exception": false,
     "start_time": "2025-01-10T10:23:13.445275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rtdl_num_embeddings -q --no-index --find-links=/kaggle/input/jane-street-import/rtdl_num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06a8c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:22.856226Z",
     "iopub.status.busy": "2025-01-10T10:23:22.855923Z",
     "iopub.status.idle": "2025-01-10T10:23:33.879853Z",
     "shell.execute_reply": "2025-01-10T10:23:33.879125Z"
    },
    "papermill": {
     "duration": 11.031836,
     "end_time": "2025-01-10T10:23:33.881698",
     "exception": false,
     "start_time": "2025-01-10T10:23:22.849862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, gc\n",
    "import pickle\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "\n",
    "import warnings\n",
    "import joblib\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor, Booster\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "sys.path.append(\"/kaggle/input/jane-street-real-time-market-data-forecasting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b1fa2",
   "metadata": {
    "papermill": {
     "duration": 0.005737,
     "end_time": "2025-01-10T10:23:33.892464",
     "exception": false,
     "start_time": "2025-01-10T10:23:33.886727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Top Public Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416de7e0",
   "metadata": {
    "papermill": {
     "duration": 0.004373,
     "end_time": "2025-01-10T10:23:33.901445",
     "exception": false,
     "start_time": "2025-01-10T10:23:33.897072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## JS|NNx5+XGBx5(MyTrain+Pub)|WeightBlend|LB.0.0078 (hideyukizushi)\n",
    "\n",
    "`LB: 0.0078` https://www.kaggle.com/code/yunsuxiaozi/js2024-starter?scriptVersionId=206770572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2e7003",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:33.912707Z",
     "iopub.status.busy": "2025-01-10T10:23:33.912132Z",
     "iopub.status.idle": "2025-01-10T10:23:37.140883Z",
     "shell.execute_reply": "2025-01-10T10:23:37.140148Z"
    },
    "papermill": {
     "duration": 3.236889,
     "end_time": "2025-01-10T10:23:37.142927",
     "exception": false,
     "start_time": "2025-01-10T10:23:33.906038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    \"\"\"Configuration class for model parameters\"\"\"\n",
    "    seed = 42  # Random seed for reproducibility\n",
    "    target_col = \"responder_6\"  # Target variable name\n",
    "    # Features: 79 base features + 9 lagged features\n",
    "    feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    # Paths to pre-trained models\n",
    "    model_paths = [\n",
    "        \"/kaggle/input/js-xs-nn-trained-model\",  # Neural Network models\n",
    "        \"/kaggle/input/js-with-lags-trained-xgb/result.pkl\", # XGBoost model\n",
    "        \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result0.pkl\",\n",
    "        \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result1.pkl\",\n",
    "        \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result2.pkl\",\n",
    "        \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result3.pkl\",\n",
    "        \"/kaggle/input/als-e-106-pp0-40-xgb-5fold/result4.pkl\"  \n",
    "    ]\n",
    "\n",
    "# Load validation data\n",
    "valid = pl.scan_parquet(f\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet/\").collect().to_pandas()\n",
    "\n",
    "# Load XGBoost model\n",
    "xgb_model = None\n",
    "with open(CONFIG.model_paths[2], \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model = result[\"model\"]\n",
    "xgb_feature_cols = [\"symbol_id\", \"time_id\"] + CONFIG.feature_cols\n",
    "\n",
    "xgb_model2 = None\n",
    "with open(CONFIG.model_paths[4], \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model2 = result[\"model\"]\n",
    "\n",
    "xgb_model4 = None\n",
    "with open(CONFIG.model_paths[6], \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model4 = result[\"model\"]\n",
    "\n",
    "xgb_model5 = None\n",
    "with open(CONFIG.model_paths[1], \"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "    xgb_model5 = result[\"model\"]\n",
    "\n",
    "def r2_val(y_true, y_pred, sample_weight):\n",
    "    \"\"\"\n",
    "    Calculate weighted R² score\n",
    "    Args:\n",
    "        y_true: True values\n",
    "        y_pred: Predicted values\n",
    "        sample_weight: Weights for each sample\n",
    "    Returns:\n",
    "        Weighted R² score\n",
    "    \"\"\"\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    return r2\n",
    "\n",
    "class NN(LightningModule):\n",
    "    \"\"\"Neural Network model using PyTorch Lightning\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        \"\"\"\n",
    "        Initialize the neural network\n",
    "        Args:\n",
    "            input_dim: Input feature dimension\n",
    "            hidden_dims: List of hidden layer dimensions\n",
    "            dropouts: List of dropout rates\n",
    "            lr: Learning rate\n",
    "            weight_decay: Weight decay for regularization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Build network architecture\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))  # Batch normalization\n",
    "            if i > 0:\n",
    "                layers.append(nn.SiLU())  # SiLU activation (except first layer)\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))  # Dropout for regularization\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))  # Linear layer\n",
    "            in_dim = hidden_dim\n",
    "            \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        layers.append(nn.Tanh())  # Tanh activation for bounded output\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass with scaling\"\"\"\n",
    "        return 5 * self.model(x).squeeze(-1)  # Scale output to [-5, 5] range\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w  # Weighted MSE loss\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Single validation step\"\"\"\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Compute validation metrics at epoch end\"\"\"\n",
    "        if not self.trainer.sanity_checking:\n",
    "            y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer and learning rate scheduler\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=5, \n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Log metrics at end of training epoch\"\"\"\n",
    "        if not self.trainer.sanity_checking:\n",
    "            epoch = self.trainer.current_epoch\n",
    "            metrics = {k: v.item() if isinstance(v, torch.Tensor) else v \n",
    "                      for k, v in self.trainer.logged_metrics.items()}\n",
    "            formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "            print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "\n",
    "# Load ensemble of models (5-fold cross-validation)\n",
    "N_folds = 5\n",
    "models = []\n",
    "for fold in range(N_folds):\n",
    "    checkpoint_path = f\"{CONFIG.model_paths[0]}/nn_{fold}.model\"\n",
    "    model = NN.load_from_checkpoint(checkpoint_path)\n",
    "    models.append(model.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7c107d",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:37.153850Z",
     "iopub.status.busy": "2025-01-10T10:23:37.153555Z",
     "iopub.status.idle": "2025-01-10T10:23:37.356616Z",
     "shell.execute_reply": "2025-01-10T10:23:37.355956Z"
    },
    "papermill": {
     "duration": 0.210293,
     "end_time": "2025-01-10T10:23:37.358210",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.147917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear validation data from memory to free up space\n",
    "#del valid\n",
    "gc.collect()\n",
    "\n",
    "# Global variable to store lagged features\n",
    "lags_: pl.DataFrame | None = None\n",
    "\n",
    "def predict_nn_xgb(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Make predictions using ensemble of XGBoost and Neural Network models\n",
    "    \n",
    "    Args:\n",
    "        test: DataFrame containing test data\n",
    "        lags: DataFrame containing lagged features (optional)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    global lags_\n",
    "    \n",
    "    # Store lags in global variable if provided\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    # Initialize predictions DataFrame with row_id and placeholder predictions\n",
    "    predictions_nn = test.select('row_id', pl.lit(0.0).alias('responder_6',))\n",
    "\n",
    "    # Process lagged features\n",
    "    # Get last record for each date_id and symbol_id combination\n",
    "    lags = lags_.clone().group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n",
    "    \n",
    "    # Join test data with lagged features\n",
    "    test = test.join(lags, on=[\"date_id\", \"symbol_id\"], how=\"left\")\n",
    "\n",
    "    # Initialize arrays for model predictions\n",
    "    preds_xgb = np.zeros((test.shape[0],))  # XGBoost predictions\n",
    "    preds_nn = np.zeros((test.shape[0],))   # Neural Network predictions\n",
    "\n",
    "    # Generate XGBoost predictions\n",
    "    preds_xgb += xgb_model.predict(test[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    preds_xgb += xgb_model2.predict(test[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    preds_xgb += xgb_model4.predict(test[xgb_feature_cols].to_pandas()) * 0.25\n",
    "    preds_xgb += xgb_model5.predict(test[xgb_feature_cols].to_pandas()) * 0.25\n",
    "\n",
    "    # Generate Neural Network predictions\n",
    "    # Prepare input data\n",
    "    test_input = test[CONFIG.feature_cols].to_pandas()\n",
    "    # Handle missing values: forward fill then fill remaining with zeros\n",
    "    test_input = test_input.fillna(method='ffill').fillna(0)\n",
    "    # Convert to PyTorch tensor and move to GPU\n",
    "    test_input = torch.FloatTensor(test_input.values).to(\"cuda:0\")\n",
    "\n",
    "    # Generate predictions from Neural Network ensemble\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        for i, nn_model in enumerate(models):\n",
    "            nn_model.eval()  # Set model to evaluation mode\n",
    "            # Average predictions from all models\n",
    "            preds_nn += nn_model(test_input).cpu().numpy() / len(models)\n",
    "\n",
    "    # Combine predictions with equal weights (50% XGBoost, 50% Neural Network)\n",
    "    preds = 0.55 * preds_xgb + 0.45 * preds_nn\n",
    "\n",
    "    # Create final predictions DataFrame\n",
    "    predictions_nn = test.select('row_id').\\\n",
    "        with_columns(\n",
    "            pl.Series(\n",
    "                name='responder_6',\n",
    "                values=np.clip(preds, a_min=-5, a_max=5),  # Clip predictions to [-5, 5] range\n",
    "                dtype=pl.Float64,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return predictions_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbfcdc",
   "metadata": {
    "papermill": {
     "duration": 0.004571,
     "end_time": "2025-01-10T10:23:37.367684",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.363113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Jane Street | TabM/FT-Transformer inference (i2nfinit3y)\n",
    "`LB: 0.0074` https://www.kaggle.com/code/i2nfinit3y/jane-street-tabm-ft-transformer-inference?scriptVersionId=213715783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d2a4f5",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:37.378201Z",
     "iopub.status.busy": "2025-01-10T10:23:37.377921Z",
     "iopub.status.idle": "2025-01-10T10:23:37.622511Z",
     "shell.execute_reply": "2025-01-10T10:23:37.621789Z"
    },
    "papermill": {
     "duration": 0.25244,
     "end_time": "2025-01-10T10:23:37.624707",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.372267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\n",
    "\n",
    "target_col = \"responder_6\" \n",
    "\n",
    "feature_test = feature_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_test if item not in feature_cat]\n",
    "\n",
    "batch_size = 8192\n",
    "\n",
    "std_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/my-own-js/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])\n",
    "\n",
    "category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n",
    " 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n",
    " 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n",
    "  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n",
    " 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n",
    "  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n",
    " 'time_id' : {i : i for i in range(968)}}\n",
    "\n",
    "def encode_column(df, column, mapping):\n",
    "    max_value = max(mapping.values())  \n",
    "\n",
    "    def encode_category(category):\n",
    "        return mapping.get(category, max_value + 1)  \n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column).map_elements(encode_category).alias(column)\n",
    "    )\n",
    "\n",
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = torch.sum((y_pred - y_true) ** 2)\n",
    "        var_y = torch.sum(y_true ** 2)\n",
    "        loss = mse_loss / (var_y + 1e-38)\n",
    "        return loss\n",
    "\n",
    "class NN(LightningModule):\n",
    "    def __init__(self, n_cont_features, cat_cardinalities, n_classes, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.k = 16\n",
    "        self.model = Model(\n",
    "                n_num_features=n_cont_features,\n",
    "                cat_cardinalities=cat_cardinalities,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    'type': 'MLP',\n",
    "                    'n_blocks': 3 ,\n",
    "                    'd_block': 512,\n",
    "                    'dropout': 0.25,\n",
    "                },\n",
    "                bins=None,\n",
    "                num_embeddings= None,\n",
    "                arch_type='tabm',\n",
    "                k=self.k,\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.loss_fn = R2Loss()\n",
    "        # self.loss_fn = weighted_mse_loss\n",
    "\n",
    "    def forward(self, x_cont, x_cat):\n",
    "        return self.model(x_cont, x_cat).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x_cont,x_cat, y, w , w_y= batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.training_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x_cont,x_cat, y, w, w_y = batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.validation_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n",
    "        #                                                        verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            # 'lr_scheduler': {\n",
    "            #     'scheduler': scheduler,\n",
    "            #     'monitor': 'val_r_square',\n",
    "            # }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "\n",
    "        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n",
    "        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        # r2_training\n",
    "        train_r_square = r2_val(y, prob, weights)\n",
    "        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "        \n",
    "class custom_args():\n",
    "    def __init__(self):\n",
    "        self.usegpu = True\n",
    "        self.gpuid = 0\n",
    "        self.seed = 42\n",
    "        self.model = 'nn'\n",
    "        self.use_wandb = False\n",
    "        self.project = 'js-tabm-with-lags'\n",
    "        self.dname = \"./input_df/\"\n",
    "        self.loader_workers = 10   \n",
    "        self.bs = 8192\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 8e-4\n",
    "        self.n_cont_features = 84\n",
    "        self.n_cat_features = 5\n",
    "        self.n_classes = None\n",
    "        self.cat_cardinalities = [23, 10, 32, 40, 969]\n",
    "        self.patience = 7\n",
    "        self.max_epochs = 10\n",
    "        self.N_fold = 5\n",
    "\n",
    "\n",
    "my_args = custom_args()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NN.load_from_checkpoint('/kaggle/input/my-own-js/tabm_epochepoch03.ckpt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba74b664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:37.635988Z",
     "iopub.status.busy": "2025-01-10T10:23:37.635548Z",
     "iopub.status.idle": "2025-01-10T10:23:37.646197Z",
     "shell.execute_reply": "2025-01-10T10:23:37.645416Z"
    },
    "papermill": {
     "duration": 0.01811,
     "end_time": "2025-01-10T10:23:37.647772",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.629662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "lags_history = None\n",
    "\n",
    "def predict_tabm(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_, lags_history\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "    \n",
    "    for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "        test = encode_column(test, col, category_mappings[col])\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    \n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "\n",
    "    time_id = test.select(\"time_id\").to_numpy()[0]\n",
    "    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n",
    "    \n",
    "    \n",
    "    if time_id == 0:\n",
    "        lags = lags.with_columns(pl.col('time_id').cast(pl.Int64))\n",
    "        lags = lags.with_columns(pl.col('symbol_id').cast(pl.Int64))\n",
    "    \n",
    "        lags_history = lags\n",
    "        lags = lags.filter(pl.col(\"time_id\") == 0)\n",
    "        \n",
    "        \n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        lags = lags_history.filter(pl.col(\"time_id\") == time_id)\n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "\n",
    "    \n",
    "    test = test.with_columns([\n",
    "        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "    ])\n",
    "\n",
    "    test = standardize(test, std_feature, means, stds)\n",
    "\n",
    "\n",
    "    X_test = test[feature_test].to_numpy()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n",
    "    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n",
    "    X_cat = X_test_tensor[:, [9, 10, 11]]\n",
    "    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n",
    "    # X_cont = X_cont + torch.randn_like(X_cont) * 0.02\n",
    "\n",
    "    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs = model(X_cont, X_cat)\n",
    "        # Assuming the model outputs a tensor of shape (batch_size, 1)\n",
    "        preds = outputs.squeeze(-1).cpu().numpy()\n",
    "        preds = preds.mean(1)\n",
    "    \n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fa0ae",
   "metadata": {
    "papermill": {
     "duration": 0.004424,
     "end_time": "2025-01-10T10:23:37.656789",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.652365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## JS Ridge baseline (yunsuxiaozi)\n",
    "\n",
    "`LB: 0.0042` https://www.kaggle.com/code/yunsuxiaozi/js-ridge-baseline?scriptVersionId=202938352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4282e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:37.666973Z",
     "iopub.status.busy": "2025-01-10T10:23:37.666707Z",
     "iopub.status.idle": "2025-01-10T10:23:37.676409Z",
     "shell.execute_reply": "2025-01-10T10:23:37.675587Z"
    },
    "papermill": {
     "duration": 0.016816,
     "end_time": "2025-01-10T10:23:37.678108",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.661292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_from_dill(model_name, model_path=None, file_ext='.dill'):\n",
    "    \"\"\"\n",
    "    Load a model from a dill file\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model file (without extension)\n",
    "        model_path: Directory path containing the model file\n",
    "        file_ext: File extension (default: '.dill')\n",
    "        \n",
    "    Returns:\n",
    "        Loaded model object\n",
    "    \"\"\"\n",
    "    model_object = None\n",
    "    # Open and load the model file using dill\n",
    "    with open(f\"{model_path}/{model_name}{file_ext}\", \"rb\") as file_handle:\n",
    "        model_object = dill.load(file_handle)\n",
    "    return model_object\n",
    "\n",
    "# Load pre-trained Ridge Regression model\n",
    "rdg = load_from_dill(\n",
    "    model_name='Ridge', \n",
    "    model_path=\"/kaggle/input/jsridgev01011635\"\n",
    ")\n",
    "\n",
    "def predict_ridge(test, lags):\n",
    "    \"\"\"\n",
    "    Make predictions using Ridge Regression model\n",
    "    \n",
    "    Args:\n",
    "        test: DataFrame containing test data\n",
    "        lags: DataFrame containing lagged features (unused in this function)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    # Select the 79 numerical features\n",
    "    cols = [f'feature_{i:02}' for i in range(79)]\n",
    "\n",
    "    # Initialize predictions DataFrame with row_id and placeholder predictions\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "\n",
    "    # Generate predictions:\n",
    "    # 1. Select required features\n",
    "    # 2. Convert to pandas\n",
    "    # 3. Fill missing values with 3\n",
    "    # 4. Make predictions using Ridge model\n",
    "    test_preds = rdg.predict(test[cols].to_pandas().fillna(3).values)\n",
    "\n",
    "    # Add predictions to result DataFrame\n",
    "    predictions = predictions.with_columns(pl.Series('responder_6', test_preds.ravel()))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80eccc",
   "metadata": {
    "papermill": {
     "duration": 0.004485,
     "end_time": "2025-01-10T10:23:37.687255",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.682770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf839b7",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:37.697418Z",
     "iopub.status.busy": "2025-01-10T10:23:37.697173Z",
     "iopub.status.idle": "2025-01-10T10:23:37.703527Z",
     "shell.execute_reply": "2025-01-10T10:23:37.702864Z"
    },
    "papermill": {
     "duration": 0.013275,
     "end_time": "2025-01-10T10:23:37.705099",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.691824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Make ensemble predictions combining all three models:\n",
    "    - Neural Network + XGBoost ensemble\n",
    "    - Starter ensemble (LightGBM + CatBoost + XGBoost)\n",
    "    - Ridge Regression\n",
    "    \n",
    "    Args:\n",
    "        test: DataFrame containing test data\n",
    "        lags: DataFrame containing lagged features\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with final ensemble predictions\n",
    "    \"\"\"\n",
    "    # Get predictions from each model/ensemble\n",
    "    pd_nn_xgb = predict_nn_xgb(test, lags).to_pandas()     # Neural Network + XGBoost ensemble\n",
    "    pd_ridge = predict_ridge(test, lags).to_pandas()        # Ridge Regression\n",
    "    pd_tabm = predict_tabm(test, lags).to_pandas()  \n",
    "\n",
    "    # Rename prediction columns to avoid conflicts\n",
    "    pd_nn_xgb = pd_nn_xgb.rename(columns={'responder_6': 'col_nn_xgb'})\n",
    "    pd_ridge = pd_ridge.rename(columns={'responder_6': 'col_ridge'})\n",
    "    pd_tabm  = pd_tabm.rename(columns={'responder_6': 'col_tabm'})\n",
    "\n",
    "    # Merge all predictions based on row_id\n",
    "    pds = pd.merge(pd_nn_xgb, pd_ridge, on=['row_id'])\n",
    "    pds = pd.merge(pds, pd_tabm, on=['row_id'])\n",
    "\n",
    "    e_weights = [0.60, 0.10, 0.30]\n",
    "    # Create final weighted ensemble prediction:\n",
    "    pds['responder_6'] = (\n",
    "        pds['col_nn_xgb'] * e_weights[0] +\n",
    "        pds['col_ridge'] * e_weights[1] +\n",
    "        pds['col_tabm'] * e_weights[2]\n",
    "    )\n",
    "\n",
    "    # Create final predictions DataFrame in required format\n",
    "    predictions = test.select('row_id', pl.lit(0.0).alias('responder_6'))\n",
    "    pred = pds['responder_6'].to_numpy()\n",
    "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18488d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T10:23:37.715229Z",
     "iopub.status.busy": "2025-01-10T10:23:37.714974Z",
     "iopub.status.idle": "2025-01-10T10:23:38.743113Z",
     "shell.execute_reply": "2025-01-10T10:23:38.742306Z"
    },
    "papermill": {
     "duration": 1.035645,
     "end_time": "2025-01-10T10:23:38.745318",
     "exception": false,
     "start_time": "2025-01-10T10:23:37.709673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:23:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import kaggle_evaluation.jane_street_inference_server\n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ea6ac",
   "metadata": {
    "papermill": {
     "duration": 0.004726,
     "end_time": "2025-01-10T10:23:38.755483",
     "exception": false,
     "start_time": "2025-01-10T10:23:38.750757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6006872,
     "sourceId": 9801075,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6010899,
     "sourceId": 9806342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6258261,
     "sourceId": 10139918,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6258265,
     "sourceId": 10139922,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6297065,
     "sourceId": 10253875,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6378806,
     "sourceId": 10304887,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6410107,
     "sourceId": 10351700,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 203900450,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 215616115,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216017958,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216577393,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.711114,
   "end_time": "2025-01-10T10:23:41.514996",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-10T10:23:10.803882",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "252dd2de87de42f4becd877fbbafc26b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff55584ae0ab4f39ae471f314eaad988",
       "placeholder": "​",
       "style": "IPY_MODEL_b8d338c473aa4dc3ba25f37a997a9037",
       "value": " 1/1 [00:00&lt;00:00, 33.79it/s]"
      }
     },
     "48a2731fb59b4ce8ace5b53d6f0e3337": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8dbc79c7c5a48318466a102c55801bb",
       "placeholder": "​",
       "style": "IPY_MODEL_ebd06aaaa7024a1684ba1b9fe89358cf",
       "value": "100%"
      }
     },
     "56da652f3eeb42aca986e6fd815629dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5bb4e0df01c44716afebab25aafe9f5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4e41234b0cc4f3e9313d971f5aadc9f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6408698650f74dd699bcc914b850e396",
       "value": 1
      }
     },
     "6408698650f74dd699bcc914b850e396": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9cb493ec04fc4ed391f5ac28cc84500e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_48a2731fb59b4ce8ace5b53d6f0e3337",
        "IPY_MODEL_5bb4e0df01c44716afebab25aafe9f5f",
        "IPY_MODEL_252dd2de87de42f4becd877fbbafc26b"
       ],
       "layout": "IPY_MODEL_56da652f3eeb42aca986e6fd815629dc"
      }
     },
     "a8dbc79c7c5a48318466a102c55801bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8d338c473aa4dc3ba25f37a997a9037": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ebd06aaaa7024a1684ba1b9fe89358cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f4e41234b0cc4f3e9313d971f5aadc9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff55584ae0ab4f39ae471f314eaad988": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
