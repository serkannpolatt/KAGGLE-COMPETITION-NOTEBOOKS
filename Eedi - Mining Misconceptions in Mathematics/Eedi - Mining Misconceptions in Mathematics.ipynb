{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49f314c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:49:38.370425Z",
     "iopub.status.busy": "2024-11-23T19:49:38.369830Z",
     "iopub.status.idle": "2024-11-23T19:53:04.489408Z",
     "shell.execute_reply": "2024-11-23T19:53:04.488450Z"
    },
    "papermill": {
     "duration": 206.126057,
     "end_time": "2024-11-23T19:53:04.491115",
     "exception": false,
     "start_time": "2024-11-23T19:49:38.365058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.0\r\n",
      "Uninstalling torch-2.4.0:\r\n",
      "  Successfully uninstalled torch-2.4.0\r\n",
      "Processing /kaggle/input/logits-processor-zoo/logits_processor_zoo-0.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: logits-processor-zoo\r\n",
      "Successfully installed logits-processor-zoo-0.1.0\r\n",
      "CPU times: user 2.07 s, sys: 534 ms, total: 2.61 s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip uninstall -y torch\n",
    "!pip install -q --no-index --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-vllm vllm\n",
    "!pip install -q -U /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -q -U /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\n",
    "!pip install -q --no-deps --no-index /kaggle/input/hf-libraries/sentence-transformers/sentence_transformers-3.1.0-py3-none-any.whl\n",
    "!pip install --no-deps --no-index /kaggle/input/logits-processor-zoo/logits_processor_zoo-0.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4414ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:53:04.500775Z",
     "iopub.status.busy": "2024-11-23T19:53:04.500482Z",
     "iopub.status.idle": "2024-11-23T19:53:12.938608Z",
     "shell.execute_reply": "2024-11-23T19:53:12.937652Z"
    },
    "papermill": {
     "duration": 8.445458,
     "end_time": "2024-11-23T19:53:12.940827",
     "exception": false,
     "start_time": "2024-11-23T19:53:04.495369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers peft accelerate \\\n",
    "    -q -U --no-index --find-links /kaggle/input/lmsys-wheel-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0553f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:53:12.950755Z",
     "iopub.status.busy": "2024-11-23T19:53:12.950463Z",
     "iopub.status.idle": "2024-11-23T19:53:54.474636Z",
     "shell.execute_reply": "2024-11-23T19:53:54.473681Z"
    },
    "papermill": {
     "duration": 41.53127,
     "end_time": "2024-11-23T19:53:54.476701",
     "exception": false,
     "start_time": "2024-11-23T19:53:12.945431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --no-index /kaggle/input/bitsandbytes0-42-0/bitsandbytes-0.42.0-py3-none-any.whl --find-links=/kaggle/input/bitsandbytes0-42-0\n",
    "!pip install --no-index  /kaggle/input/bitsandbytes0-42-0/optimum-1.21.2-py3-none-any.whl --find-links=/kaggle/input/bitsandbytes0-42-0\n",
    "!pip install --no-index  /kaggle/input/bitsandbytes0-42-0/auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --find-links=/kaggle/input/bitsandbytes0-42-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c10f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:53:54.486836Z",
     "iopub.status.busy": "2024-11-23T19:53:54.486305Z",
     "iopub.status.idle": "2024-11-23T19:53:55.167365Z",
     "shell.execute_reply": "2024-11-23T19:53:55.166510Z"
    },
    "papermill": {
     "duration": 0.688104,
     "end_time": "2024-11-23T19:53:55.169154",
     "exception": false,
     "start_time": "2024-11-23T19:53:54.481050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>incorrect_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### SubjectName: BIDMAS\\n### ConstructName: Us...</td>\n",
       "      <td>1869_B</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\( 3 \\times 2+(4-5) \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### SubjectName: BIDMAS\\n### ConstructName: Us...</td>\n",
       "      <td>1869_C</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\( 3 \\times(2+4-5) \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### SubjectName: BIDMAS\\n### ConstructName: Us...</td>\n",
       "      <td>1869_D</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>Does not need brackets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### SubjectName: Simplifying Algebraic Fractio...</td>\n",
       "      <td>1870_A</td>\n",
       "      <td>Simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>Simplifying Algebraic Fractions</td>\n",
       "      <td>Simplify the following, if possible: \\( \\frac{...</td>\n",
       "      <td>Does not simplify</td>\n",
       "      <td>\\( m+1 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### SubjectName: Simplifying Algebraic Fractio...</td>\n",
       "      <td>1870_B</td>\n",
       "      <td>Simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>Simplifying Algebraic Fractions</td>\n",
       "      <td>Simplify the following, if possible: \\( \\frac{...</td>\n",
       "      <td>Does not simplify</td>\n",
       "      <td>\\( m+2 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>### SubjectName: Simplifying Algebraic Fractio...</td>\n",
       "      <td>1870_C</td>\n",
       "      <td>Simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>Simplifying Algebraic Fractions</td>\n",
       "      <td>Simplify the following, if possible: \\( \\frac{...</td>\n",
       "      <td>Does not simplify</td>\n",
       "      <td>\\( m-1 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>### SubjectName: Range and Interquartile Range...</td>\n",
       "      <td>1871_A</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n",
       "      <td>Only\\nKatie</td>\n",
       "      <td>Only\\nTom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>### SubjectName: Range and Interquartile Range...</td>\n",
       "      <td>1871_C</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n",
       "      <td>Only\\nKatie</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>### SubjectName: Range and Interquartile Range...</td>\n",
       "      <td>1871_D</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n",
       "      <td>Only\\nKatie</td>\n",
       "      <td>Neither is correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text QuestionId_Answer  \\\n",
       "0  ### SubjectName: BIDMAS\\n### ConstructName: Us...            1869_B   \n",
       "1  ### SubjectName: BIDMAS\\n### ConstructName: Us...            1869_C   \n",
       "2  ### SubjectName: BIDMAS\\n### ConstructName: Us...            1869_D   \n",
       "3  ### SubjectName: Simplifying Algebraic Fractio...            1870_A   \n",
       "4  ### SubjectName: Simplifying Algebraic Fractio...            1870_B   \n",
       "5  ### SubjectName: Simplifying Algebraic Fractio...            1870_C   \n",
       "6  ### SubjectName: Range and Interquartile Range...            1871_A   \n",
       "7  ### SubjectName: Range and Interquartile Range...            1871_C   \n",
       "8  ### SubjectName: Range and Interquartile Range...            1871_D   \n",
       "\n",
       "                                       ConstructName  \\\n",
       "0  Use the order of operations to carry out calcu...   \n",
       "1  Use the order of operations to carry out calcu...   \n",
       "2  Use the order of operations to carry out calcu...   \n",
       "3  Simplify an algebraic fraction by factorising ...   \n",
       "4  Simplify an algebraic fraction by factorising ...   \n",
       "5  Simplify an algebraic fraction by factorising ...   \n",
       "6            Calculate the range from a list of data   \n",
       "7            Calculate the range from a list of data   \n",
       "8            Calculate the range from a list of data   \n",
       "\n",
       "                                         SubjectName  \\\n",
       "0                                             BIDMAS   \n",
       "1                                             BIDMAS   \n",
       "2                                             BIDMAS   \n",
       "3                    Simplifying Algebraic Fractions   \n",
       "4                    Simplifying Algebraic Fractions   \n",
       "5                    Simplifying Algebraic Fractions   \n",
       "6  Range and Interquartile Range from a List of Data   \n",
       "7  Range and Interquartile Range from a List of Data   \n",
       "8  Range and Interquartile Range from a List of Data   \n",
       "\n",
       "                                        QuestionText         correct_answer  \\\n",
       "0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n",
       "1  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n",
       "2  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n",
       "3  Simplify the following, if possible: \\( \\frac{...      Does not simplify   \n",
       "4  Simplify the following, if possible: \\( \\frac{...      Does not simplify   \n",
       "5  Simplify the following, if possible: \\( \\frac{...      Does not simplify   \n",
       "6  Tom and Katie are discussing the \\( 5 \\) plant...            Only\\nKatie   \n",
       "7  Tom and Katie are discussing the \\( 5 \\) plant...            Only\\nKatie   \n",
       "8  Tom and Katie are discussing the \\( 5 \\) plant...            Only\\nKatie   \n",
       "\n",
       "         incorrect_answer  \n",
       "0  \\( 3 \\times 2+(4-5) \\)  \n",
       "1   \\( 3 \\times(2+4-5) \\)  \n",
       "2  Does not need brackets  \n",
       "3               \\( m+1 \\)  \n",
       "4               \\( m+2 \\)  \n",
       "5               \\( m-1 \\)  \n",
       "6               Only\\nTom  \n",
       "7      Both Tom and Katie  \n",
       "8      Neither is correct  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "full_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n",
    "IS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "\n",
    "rows = []\n",
    "for idx, row in full_df.iterrows():\n",
    "    for option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        if option == row.CorrectAnswer:\n",
    "            continue\n",
    "            \n",
    "        correct_answer = row[f\"Answer{row.CorrectAnswer}Text\"]\n",
    "\n",
    "        query_text =f\"### SubjectName: {row['SubjectName']}\\n### ConstructName: {row['ConstructName']}\\n### Question: {row['QuestionText']}\\n### Correct Answer: {correct_answer}\\n### Misconcepte Incorrect answer: {option}.{row[f'Answer{option}Text']}\"\n",
    "        rows.append({\"query_text\": query_text, \n",
    "                     \"QuestionId_Answer\": f\"{row.QuestionId}_{option}\",\n",
    "                     \"ConstructName\": row.ConstructName,\n",
    "                     \"SubjectName\": row.SubjectName,\n",
    "                     \"QuestionText\": row.QuestionText,\n",
    "                     \"correct_answer\": correct_answer,\n",
    "                     \"incorrect_answer\": row[f\"Answer{option}Text\"]\n",
    "                     })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b9abd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:53:55.180054Z",
     "iopub.status.busy": "2024-11-23T19:53:55.179803Z",
     "iopub.status.idle": "2024-11-23T19:53:59.946398Z",
     "shell.execute_reply": "2024-11-23T19:53:59.945454Z"
    },
    "papermill": {
     "duration": 4.774419,
     "end_time": "2024-11-23T19:53:59.948539",
     "exception": false,
     "start_time": "2024-11-23T19:53:55.174120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForMaskedLM, AutoModel, BitsAndBytesConfig\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def batch_to_device(batch, target_device):\n",
    "    \"\"\"\n",
    "    send a pytorch batch to a device (CPU/GPU)\n",
    "    \"\"\"\n",
    "    for key in batch:\n",
    "        if isinstance(batch[key], Tensor):\n",
    "            batch[key] = batch[key].to(target_device)\n",
    "    return batch\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                    attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "def inference(df, model, tokenizer, device):\n",
    "    batch_size = 16\n",
    "    max_length = 512\n",
    "    sentences = list(df['query_text'].values)\n",
    "\n",
    "    all_embeddings = []\n",
    "    length_sorted_idx = np.argsort([-len(sen) for sen in sentences])\n",
    "    sentences_sorted = [sentences[idx] for idx in length_sorted_idx]\n",
    "    for start_index in trange(0, len(sentences), batch_size, desc=\"Batches\", disable=False):\n",
    "        sentences_batch = sentences_sorted[start_index: start_index + batch_size]\n",
    "        features = tokenizer(sentences_batch, max_length=max_length, padding=True, truncation=True,\n",
    "                             return_tensors=\"pt\")\n",
    "        features = batch_to_device(features, device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**features)\n",
    "            embeddings = last_token_pool(outputs.last_hidden_state, features['attention_mask'])\n",
    "            embeddings = torch.nn.functional.normalize(embeddings, dim=-1)\n",
    "            embeddings = embeddings.detach().cpu().numpy().tolist()\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    all_embeddings = [np.array(all_embeddings[idx]).reshape(1, -1) for idx in np.argsort(length_sorted_idx)]\n",
    "\n",
    "    return np.concatenate(all_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7616321d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:53:59.962676Z",
     "iopub.status.busy": "2024-11-23T19:53:59.961864Z",
     "iopub.status.idle": "2024-11-23T19:53:59.966385Z",
     "shell.execute_reply": "2024-11-23T19:53:59.965599Z"
    },
    "papermill": {
     "duration": 0.012187,
     "end_time": "2024-11-23T19:53:59.967892",
     "exception": false,
     "start_time": "2024-11-23T19:53:59.955705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_prefix = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n",
    "model_path = \"/kaggle/input/qwen2.5-14/pytorch/default/1\"\n",
    "\n",
    "lora_path='/kaggle/input/qwen14b-it-lora/lora_weights/adapter.bin'\n",
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666fa215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:53:59.977930Z",
     "iopub.status.busy": "2024-11-23T19:53:59.977633Z",
     "iopub.status.idle": "2024-11-23T19:57:28.457037Z",
     "shell.execute_reply": "2024-11-23T19:57:28.455960Z"
    },
    "papermill": {
     "duration": 208.487218,
     "end_time": "2024-11-23T19:57:28.459378",
     "exception": false,
     "start_time": "2024-11-23T19:53:59.972160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177bb83fe032496d8b9d1205e9e431a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading lora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(lora_path.replace(\"/adapter.bin\",\"\"))\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "model_base = AutoModel.from_pretrained(model_path, \n",
    "                                  quantization_config=bnb_config, \n",
    "                                  device_map=device,\n",
    "                                  trust_remote_code=True)\n",
    "\n",
    "if lora_path:\n",
    "    print(\"loading lora\")\n",
    "    config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=128,\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "        ],\n",
    "        bias=\"none\",\n",
    "        lora_dropout=0.05,  # Conventional\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "    )\n",
    "    model = get_peft_model(model_base, config)\n",
    "    d = torch.load(lora_path, map_location=model.device)\n",
    "    model.load_state_dict(d, strict=False)\n",
    "    model = model.merge_and_unload()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c04e6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:57:28.470275Z",
     "iopub.status.busy": "2024-11-23T19:57:28.469962Z",
     "iopub.status.idle": "2024-11-23T19:58:19.690329Z",
     "shell.execute_reply": "2024-11-23T19:58:19.689391Z"
    },
    "papermill": {
     "duration": 51.227525,
     "end_time": "2024-11-23T19:58:19.692031",
     "exception": false,
     "start_time": "2024-11-23T19:57:28.464506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c0e63ff75e40caaaf144833d62b28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df15fe27956f4c9b847de0cde014dcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((9, 5120), (100, 5120))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.autonotebook import trange\n",
    "\n",
    "\n",
    "task_description = 'Given a math question with correct answer and a misconcepted incorrect answer, retrieve the most accurate misconception for the incorrect answer.'\n",
    "df['query_text'] = df['query_text'].apply(lambda x: get_detailed_instruct(task_description,x))\n",
    "V_answer = inference(df, model, tokenizer, device)\n",
    "\n",
    "misconception_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n",
    "misconception_df[\"query_text\"] = misconception_df[\"MisconceptionName\"]\n",
    "if not IS_SUBMISSION:\n",
    "    misconception_df = misconception_df[:100]\n",
    "\n",
    "\n",
    "V_misconception = inference(misconception_df, model, tokenizer, device)\n",
    "\n",
    "V_answer.shape,V_misconception.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36dcfd6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:58:19.705052Z",
     "iopub.status.busy": "2024-11-23T19:58:19.704318Z",
     "iopub.status.idle": "2024-11-23T19:58:19.740018Z",
     "shell.execute_reply": "2024-11-23T19:58:19.739175Z"
    },
    "papermill": {
     "duration": 0.04453,
     "end_time": "2024-11-23T19:58:19.741948",
     "exception": false,
     "start_time": "2024-11-23T19:58:19.697418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def get_matches(V_topic, V_content, n_neighbors=25):\n",
    "    \n",
    "    neighbors_model = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine', algorithm=\"brute\", n_jobs=-1)\n",
    "    neighbors_model.fit(V_content)\n",
    "    dists, indices = neighbors_model.kneighbors(V_topic)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "indices = get_matches(V_answer, V_misconception, n_neighbors=25)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7fc09f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:58:19.757093Z",
     "iopub.status.busy": "2024-11-23T19:58:19.756373Z",
     "iopub.status.idle": "2024-11-23T19:58:20.397018Z",
     "shell.execute_reply": "2024-11-23T19:58:20.396156Z"
    },
    "papermill": {
     "duration": 0.64971,
     "end_time": "2024-11-23T19:58:20.398866",
     "exception": false,
     "start_time": "2024-11-23T19:58:19.749156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model_base, model, tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc5c5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:58:20.410496Z",
     "iopub.status.busy": "2024-11-23T19:58:20.410172Z",
     "iopub.status.idle": "2024-11-23T19:58:20.503378Z",
     "shell.execute_reply": "2024-11-23T19:58:20.502536Z"
    },
    "papermill": {
     "duration": 0.100814,
     "end_time": "2024-11-23T19:58:20.505117",
     "exception": false,
     "start_time": "2024-11-23T19:58:20.404303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"indices.npy\", indices)\n",
    "df.to_parquet(\"df.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef57e3f",
   "metadata": {
    "papermill": {
     "duration": 0.004731,
     "end_time": "2024-11-23T19:58:20.514968",
     "exception": false,
     "start_time": "2024-11-23T19:58:20.510237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Picking the best candidate using qwen-32b-instruct-awq\n",
    "Inspired by: https://www.kaggle.com/code/takanashihumbert/eedi-qwen-2-5-32b-awq-two-time-retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7cacb4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:58:20.545599Z",
     "iopub.status.busy": "2024-11-23T19:58:20.545255Z",
     "iopub.status.idle": "2024-11-23T19:58:20.555889Z",
     "shell.execute_reply": "2024-11-23T19:58:20.554787Z"
    },
    "papermill": {
     "duration": 0.018563,
     "end_time": "2024-11-23T19:58:20.557618",
     "exception": false,
     "start_time": "2024-11-23T19:58:20.539055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_vllm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_vllm.py\n",
    "\n",
    "import vllm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer\n",
    "from typing import List\n",
    "import torch\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "import re\n",
    "\n",
    "model_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def preprocess_text(x):\n",
    "    x = re.sub(\"http\\w+\", '',x)   # Delete URL\n",
    "    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = re.sub(r\"\\\\\\(\", \" \", x)\n",
    "    x = re.sub(r\"\\\\\\)\", \" \", x)\n",
    "    x = re.sub(r\"[ ]{1,}\", \" \", x)\n",
    "    x = x.strip()                 # Remove empty characters at the beginning and end\n",
    "    return x\n",
    "\n",
    "PROMPT  = \"\"\"Here is a question about {ConstructName}({SubjectName}).\n",
    "Question: {Question}\n",
    "Correct Answer: {CorrectAnswer}\n",
    "Incorrect Answer: {IncorrectAnswer}\n",
    "\n",
    "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\n",
    "Answer concisely what misconception it is to lead to getting the incorrect answer.\n",
    "Pick the correct misconception number from the below:\n",
    "\n",
    "{Retrival}\n",
    "\"\"\"\n",
    "# just directly give your answers.\n",
    "\n",
    "def apply_template(row, tokenizer):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": preprocess_text(\n",
    "                PROMPT.format(\n",
    "                    ConstructName=row[\"ConstructName\"],\n",
    "                    SubjectName=row[\"SubjectName\"],\n",
    "                    Question=row[\"QuestionText\"],\n",
    "                    IncorrectAnswer=row[f\"incorrect_answer\"],\n",
    "                    CorrectAnswer=row[f\"correct_answer\"],\n",
    "                    Retrival=row[f\"retrieval\"]\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return text\n",
    "\n",
    "\n",
    "misconception_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n",
    "\n",
    "df = pd.read_parquet(\"df.parquet\")\n",
    "indices = np.load(\"indices.npy\")\n",
    "\n",
    "model_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "\n",
    "llm = vllm.LLM(\n",
    "    model_path,\n",
    "    quantization=\"awq\",\n",
    "    tensor_parallel_size=2,\n",
    "    gpu_memory_utilization=0.90, \n",
    "    trust_remote_code=True,\n",
    "    dtype=\"half\", \n",
    "    enforce_eager=True,\n",
    "    max_model_len=5120,\n",
    "    disable_log_stats=True\n",
    ")\n",
    "tokenizer = llm.get_tokenizer()\n",
    "\n",
    "\n",
    "def get_candidates(c_indices):\n",
    "    candidates = []\n",
    "\n",
    "    mis_names = misconception_df[\"MisconceptionName\"].values\n",
    "    for ix in c_indices:\n",
    "        c_names = []\n",
    "        for i, name in enumerate(mis_names[ix]):\n",
    "            c_names.append(f\"{i+1}. {name}\")\n",
    "\n",
    "        candidates.append(\"\\n\".join(c_names))\n",
    "        \n",
    "    return candidates\n",
    "\n",
    "survivors = indices[:, -1:]\n",
    "\n",
    "for i in range(3):\n",
    "    c_indices = np.concatenate([indices[:, -8*(i+1)-1:-8*i-1], survivors], axis=1)\n",
    "    \n",
    "    df[\"retrieval\"] = get_candidates(c_indices)\n",
    "    df[\"text\"] = df.apply(lambda row: apply_template(row, tokenizer), axis=1)\n",
    "    \n",
    "    print(\"Example:\")\n",
    "    print(df[\"text\"].values[0])\n",
    "    print()\n",
    "    \n",
    "    responses = llm.generate(\n",
    "        df[\"text\"].values,\n",
    "        vllm.SamplingParams(\n",
    "            n=1,  # Number of output sequences to return for each prompt.\n",
    "            top_k=1,  # Float that controls the cumulative probability of the top tokens to consider.\n",
    "            temperature=0,  # randomness of the sampling\n",
    "            seed=777, # Seed for reprodicibility\n",
    "            skip_special_tokens=False,  # Whether to skip special tokens in the output.\n",
    "            max_tokens=1,  # Maximum number of tokens to generate per output sequence.\n",
    "            logits_processors=[MultipleChoiceLogitsProcessor(tokenizer, choices=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])]\n",
    "        ),\n",
    "        use_tqdm=True\n",
    "    )\n",
    "    \n",
    "    responses = [x.outputs[0].text for x in responses]\n",
    "    df[\"response\"] = responses\n",
    "    \n",
    "    \n",
    "    llm_choices = df[\"response\"].astype(int).values - 1\n",
    "    \n",
    "    survivors = np.array([cix[best] for best, cix in zip(llm_choices, c_indices)]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(indices.shape[0]):\n",
    "    ix = indices[i]\n",
    "    llm_choice = survivors[i, 0]\n",
    "    \n",
    "    results.append(\" \".join([str(llm_choice)] + [str(x) for x in ix if x != llm_choice]))\n",
    "\n",
    "\n",
    "df[\"MisconceptionId\"] = results\n",
    "df.to_csv(\"submission.csv\", columns=[\"QuestionId_Answer\", \"MisconceptionId\"], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4e4153",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-11-23T19:58:20.568519Z",
     "iopub.status.busy": "2024-11-23T19:58:20.568262Z",
     "iopub.status.idle": "2024-11-23T20:00:35.314337Z",
     "shell.execute_reply": "2024-11-23T20:00:35.313376Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 134.753905,
     "end_time": "2024-11-23T20:00:35.316477",
     "exception": false,
     "start_time": "2024-11-23T19:58:20.562572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "WARNING 11-23 19:58:25 config.py:246] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\r\n",
      "INFO 11-23 19:58:25 config.py:715] Defaulting to use mp for distributed inference\r\n",
      "INFO 11-23 19:58:25 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1', speculative_config=None, tokenizer='/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=5120, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1, use_v2_block_manager=False, enable_prefix_caching=False)\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "INFO 11-23 19:58:26 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:26 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:26 selector.py:54] Using XFormers backend.\r\n",
      "INFO 11-23 19:58:26 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 11-23 19:58:26 selector.py:54] Using XFormers backend.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:27 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:28 utils.py:784] Found nccl from library libnccl.so.2\r\n",
      "INFO 11-23 19:58:28 utils.py:784] Found nccl from library libnccl.so.2\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:28 pynccl.py:63] vLLM is using nccl==2.20.5\r\n",
      "INFO 11-23 19:58:28 pynccl.py:63] vLLM is using nccl==2.20.5\r\n",
      "INFO 11-23 19:58:28 custom_all_reduce_utils.py:202] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "INFO 11-23 19:58:36 custom_all_reduce_utils.py:232] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:36 custom_all_reduce_utils.py:232] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "WARNING 11-23 19:58:36 custom_all_reduce.py:127] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m WARNING 11-23 19:58:36 custom_all_reduce.py:127] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\r\n",
      "INFO 11-23 19:58:36 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x782fc53be3e0>, local_subscribe_port=60355, local_sync_port=54953, remote_subscribe_port=None, remote_sync_port=None)\r\n",
      "INFO 11-23 19:58:36 model_runner.py:680] Starting to load model /kaggle/input/qwen2.5/transformers/32b-instruct-awq/1...\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:36 model_runner.py:680] Starting to load model /kaggle/input/qwen2.5/transformers/32b-instruct-awq/1...\r\n",
      "INFO 11-23 19:58:36 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 11-23 19:58:36 selector.py:54] Using XFormers backend.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:36 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 19:58:36 selector.py:54] Using XFormers backend.\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\r\n",
      "Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:15<01:01, 15.37s/it]\r\n",
      "Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:32<00:48, 16.29s/it]\r\n",
      "Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:50<00:34, 17.01s/it]\r\n",
      "Loading safetensors checkpoint shards:  80% Completed | 4/5 [01:07<00:17, 17.29s/it]\r\n",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [01:26<00:00, 17.88s/it]\r\n",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [01:26<00:00, 17.37s/it]\r\n",
      "\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=132)\u001b[0;0m INFO 11-23 20:00:03 model_runner.py:692] Loading model weights took 9.0933 GB\r\n",
      "INFO 11-23 20:00:03 model_runner.py:692] Loading model weights took 9.0933 GB\r\n",
      "INFO 11-23 20:00:11 distributed_gpu_executor.py:56] # GPU blocks: 815, # CPU blocks: 2048\r\n",
      "Example:\r\n",
      "<|im_start|>system\r\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "Here is a question about Use the order of operations to carry out calculations involving powers(BIDMAS).\r\n",
      "Question: \\[\r\n",
      "3 \\times 2+4-5\r\n",
      "\\]\r\n",
      "Where do the brackets need to go to make the answer equal 13 ?\r\n",
      "Correct Answer: 3 \\times(2+4)-5 \r\n",
      "Incorrect Answer: 3 \\times 2+(4-5) \r\n",
      "\r\n",
      "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\r\n",
      "Answer concisely what misconception it is to lead to getting the incorrect answer.\r\n",
      "Pick the correct misconception number from the below:\r\n",
      "\r\n",
      "1. Believes the sides of an inequality can be switched without changing the direction of the sign\r\n",
      "2. Has written the value of the 'ones' column as the answer, withiut using the numbers in the question.\r\n",
      "3. Believes greater than/less than symbols include end values\r\n",
      "4. Student thinks that any two angles along a straight line are equal\r\n",
      "5. Thinks it can't be called a sequence with a repeated number at the start\r\n",
      "6. Does not understand the term multiple\r\n",
      "7. When asked for a number n times smaller or bigger, subtracts or adds n\r\n",
      "8. Does not realise that when you multiply by 0 the answer will always be 0\r\n",
      "9. When asked for a specific term in a sequence gives the term before<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "\r\n",
      "\r\n",
      "Processed prompts: 100%|█| 9/9 [00:05<00:00,  1.65it/s, est. speed input: 521.69\r\n",
      "Example:\r\n",
      "<|im_start|>system\r\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "Here is a question about Use the order of operations to carry out calculations involving powers(BIDMAS).\r\n",
      "Question: \\[\r\n",
      "3 \\times 2+4-5\r\n",
      "\\]\r\n",
      "Where do the brackets need to go to make the answer equal 13 ?\r\n",
      "Correct Answer: 3 \\times(2+4)-5 \r\n",
      "Incorrect Answer: 3 \\times 2+(4-5) \r\n",
      "\r\n",
      "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\r\n",
      "Answer concisely what misconception it is to lead to getting the incorrect answer.\r\n",
      "Pick the correct misconception number from the below:\r\n",
      "\r\n",
      "1. Does not subtract from the hours, when having to borrow for a time calculation\r\n",
      "2. Believes that the directions of positive and negative vectors are the opposite way around.\r\n",
      "3. Believes they must expand brackets before solving an equation\r\n",
      "4. Forgot to simplify the fraction\r\n",
      "5. Confuses AM and PM when calculating time\r\n",
      "6. Confuses a function with an expression\r\n",
      "7. Believes that the complement of a set includes any elements which are also in another set.\r\n",
      "8. Does not understand how to create a multiple of an equation\r\n",
      "9. When asked for a number n times smaller or bigger, subtracts or adds n<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "\r\n",
      "\r\n",
      "Processed prompts: 100%|█| 9/9 [00:04<00:00,  1.89it/s, est. speed input: 593.55\r\n",
      "Example:\r\n",
      "<|im_start|>system\r\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "Here is a question about Use the order of operations to carry out calculations involving powers(BIDMAS).\r\n",
      "Question: \\[\r\n",
      "3 \\times 2+4-5\r\n",
      "\\]\r\n",
      "Where do the brackets need to go to make the answer equal 13 ?\r\n",
      "Correct Answer: 3 \\times(2+4)-5 \r\n",
      "Incorrect Answer: 3 \\times 2+(4-5) \r\n",
      "\r\n",
      "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\r\n",
      "Answer concisely what misconception it is to lead to getting the incorrect answer.\r\n",
      "Pick the correct misconception number from the below:\r\n",
      "\r\n",
      "1. Confuses the order of operations, believes addition comes before division\r\n",
      "2. Does not follow the arrows through a function machine, changes the order of the operations asked.\r\n",
      "3. When subtracting a negative number from a positive number, uses a method which assumes one of the negative signs can be ignored \r\n",
      "4. Does not know about the + notation for directions in rotations\r\n",
      "5. Believes the square of a negative will also be negative\r\n",
      "6. Multiplies surds when asked to add\r\n",
      "7. Believes dividing a negative by a positive gives a positive answer\r\n",
      "8. Believes addition of terms and powers of terms are equivalent e.g. a + c = a^c\r\n",
      "9. Believes they must expand brackets before solving an equation<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "\r\n",
      "\r\n",
      "Processed prompts: 100%|█| 9/9 [00:05<00:00,  1.66it/s, est. speed input: 536.12\r\n",
      "INFO 11-23 20:00:32 multiproc_worker_utils.py:123] Killing local vLLM worker processes\r\n"
     ]
    }
   ],
   "source": [
    "!python run_vllm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e37a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:00:35.330976Z",
     "iopub.status.busy": "2024-11-23T20:00:35.330668Z",
     "iopub.status.idle": "2024-11-23T20:00:35.343947Z",
     "shell.execute_reply": "2024-11-23T20:00:35.343144Z"
    },
    "papermill": {
     "duration": 0.022354,
     "end_time": "2024-11-23T20:00:35.345517",
     "exception": false,
     "start_time": "2024-11-23T20:00:35.323163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>MisconceptionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1869_B</td>\n",
       "      <td>74 15 77 55 95 82 96 34 4 13 75 29 17 73 42 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869_C</td>\n",
       "      <td>74 77 15 55 82 13 14 25 29 84 52 30 73 38 0 98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1869_D</td>\n",
       "      <td>74 15 77 55 95 14 13 24 29 73 82 0 25 52 96 4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1870_A</td>\n",
       "      <td>59 80 91 3 29 55 46 79 34 82 74 1 94 6 19 0 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1870_B</td>\n",
       "      <td>59 80 91 3 79 46 29 74 55 34 58 94 6 27 14 24 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1870_C</td>\n",
       "      <td>59 80 91 3 29 46 79 55 82 74 1 24 98 6 34 25 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1871_A</td>\n",
       "      <td>23 14 25 38 82 30 74 49 24 36 0 56 84 55 37 97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1871_C</td>\n",
       "      <td>74 25 82 14 49 38 0 62 85 56 24 30 55 36 84 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1871_D</td>\n",
       "      <td>14 0 23 56 25 18 62 74 84 24 3 38 82 85 49 87 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QuestionId_Answer                                    MisconceptionId\n",
       "0            1869_B  74 15 77 55 95 82 96 34 4 13 75 29 17 73 42 14...\n",
       "1            1869_C  74 77 15 55 82 13 14 25 29 84 52 30 73 38 0 98...\n",
       "2            1869_D  74 15 77 55 95 14 13 24 29 73 82 0 25 52 96 4 ...\n",
       "3            1870_A  59 80 91 3 29 55 46 79 34 82 74 1 94 6 19 0 44...\n",
       "4            1870_B  59 80 91 3 79 46 29 74 55 34 58 94 6 27 14 24 ...\n",
       "5            1870_C  59 80 91 3 29 46 79 55 82 74 1 24 98 6 34 25 0...\n",
       "6            1871_A  23 14 25 38 82 30 74 49 24 36 0 56 84 55 37 97...\n",
       "7            1871_C  74 25 82 14 49 38 0 62 85 56 24 30 55 36 84 23...\n",
       "8            1871_D  14 0 23 56 25 18 62 74 84 24 3 38 82 85 49 87 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf0d87",
   "metadata": {
    "papermill": {
     "duration": 0.006086,
     "end_time": "2024-11-23T20:00:35.357950",
     "exception": false,
     "start_time": "2024-11-23T20:00:35.351864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910b300",
   "metadata": {
    "papermill": {
     "duration": 0.006123,
     "end_time": "2024-11-23T20:00:35.370600",
     "exception": false,
     "start_time": "2024-11-23T20:00:35.364477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9738540,
     "sourceId": 82695,
     "sourceType": "competition"
    },
    {
     "datasetId": 4871830,
     "sourceId": 8218776,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5251603,
     "sourceId": 9094368,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5920031,
     "sourceId": 9688062,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5957531,
     "sourceId": 9734430,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6117312,
     "sourceId": 9948011,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6135443,
     "sourceId": 9972502,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4581967,
     "sourceId": 9991357,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 200567623,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 123481,
     "modelInstanceId": 99392,
     "sourceId": 118192,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 165390,
     "modelInstanceId": 142811,
     "sourceId": 167864,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 662.844485,
   "end_time": "2024-11-23T20:00:38.890670",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-23T19:49:36.046185",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04586d9a9ea14dbca5dcfb16a936842b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_823ee1e65db843e5b3f886c2dfc67639",
       "placeholder": "​",
       "style": "IPY_MODEL_770b7912641846e48aa498d08cd2af72",
       "value": "Batches: 100%"
      }
     },
     "06c5970e1332446a92656dec60934a42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e385f6b05054a00b99554f7476d9fd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84f8c9f586564b66bfc96ac394cb1c38",
       "placeholder": "​",
       "style": "IPY_MODEL_dfb525a2b5564fc6943f0e9ebee89c08",
       "value": " 7/7 [00:25&lt;00:00,  2.89s/it]"
      }
     },
     "14de6ff7c9ab474fad8684192826deb5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "177bb83fe032496d8b9d1205e9e431a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d743f62a4a3546ae91cedcc625dd4998",
        "IPY_MODEL_82cdc827cbbe4156ad8b235dd3bff0e2",
        "IPY_MODEL_e9de5cd4c06a49e5b89b491f22be945a"
       ],
       "layout": "IPY_MODEL_95f36e3a0206448680d29a5028ffc049"
      }
     },
     "2cf0e02ec31e42bbbbe7dfb52bcf8180": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3b25cd6c69b74b45957fd7cada758458",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76884f84f338452698474bdad8c20c25",
       "value": 1
      }
     },
     "3b25cd6c69b74b45957fd7cada758458": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b4d0e00a483412c9f4d37c895c243ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f5a3ad60e654a5fa901cfe275a6e3d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4af4c2071797445c93b82ded93d764e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63294073692641b5973cf41239e3eec6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6dae830812104d79993d4d7ac515c3fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74c0e63ff75e40caaaf144833d62b28f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_04586d9a9ea14dbca5dcfb16a936842b",
        "IPY_MODEL_2cf0e02ec31e42bbbbe7dfb52bcf8180",
        "IPY_MODEL_cf851e634d7940eab290de0de91ca2a4"
       ],
       "layout": "IPY_MODEL_3b4d0e00a483412c9f4d37c895c243ad"
      }
     },
     "76884f84f338452698474bdad8c20c25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "770b7912641846e48aa498d08cd2af72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a74d184c2ec4052857cf4d58a510d30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "823ee1e65db843e5b3f886c2dfc67639": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82cdc827cbbe4156ad8b235dd3bff0e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a74d184c2ec4052857cf4d58a510d30",
       "max": 8,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e4b8f8bf75904040b3921e71519711f9",
       "value": 8
      }
     },
     "84f8c9f586564b66bfc96ac394cb1c38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "855c95bbded74849be56b2a78efd15cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "89412279e78948e5b52f46c433ae9bb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_63294073692641b5973cf41239e3eec6",
       "max": 7,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fcb9596b1a2f4dc8b468f0d5aa675642",
       "value": 7
      }
     },
     "95f36e3a0206448680d29a5028ffc049": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af8a291657e9438c846747d1c84ea52f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0b3141f4c7849f0924ded75a8725b7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4af4c2071797445c93b82ded93d764e0",
       "placeholder": "​",
       "style": "IPY_MODEL_3f5a3ad60e654a5fa901cfe275a6e3d4",
       "value": "Batches: 100%"
      }
     },
     "c6e29e67f2494efcb9fb7ad168b4d1d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8ddadba8f8746529ec2fdf4967c13e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cf851e634d7940eab290de0de91ca2a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c6e29e67f2494efcb9fb7ad168b4d1d2",
       "placeholder": "​",
       "style": "IPY_MODEL_c8ddadba8f8746529ec2fdf4967c13e3",
       "value": " 1/1 [00:25&lt;00:00, 25.28s/it]"
      }
     },
     "d743f62a4a3546ae91cedcc625dd4998": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_af8a291657e9438c846747d1c84ea52f",
       "placeholder": "​",
       "style": "IPY_MODEL_855c95bbded74849be56b2a78efd15cf",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "df15fe27956f4c9b847de0cde014dcab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c0b3141f4c7849f0924ded75a8725b7d",
        "IPY_MODEL_89412279e78948e5b52f46c433ae9bb6",
        "IPY_MODEL_0e385f6b05054a00b99554f7476d9fd5"
       ],
       "layout": "IPY_MODEL_6dae830812104d79993d4d7ac515c3fe"
      }
     },
     "dfb525a2b5564fc6943f0e9ebee89c08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e4b8f8bf75904040b3921e71519711f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e9de5cd4c06a49e5b89b491f22be945a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14de6ff7c9ab474fad8684192826deb5",
       "placeholder": "​",
       "style": "IPY_MODEL_06c5970e1332446a92656dec60934a42",
       "value": " 8/8 [02:03&lt;00:00, 12.21s/it]"
      }
     },
     "fcb9596b1a2f4dc8b468f0d5aa675642": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
