## English
## Goal of the Competition
Inspired by the OpenBookQA dataset, this competition challenges participants to answer difficult science-based questions written by a Large Language Model.

Your work will help researchers better understand the ability of LLMs to test themselves, and the potential of LLMs that can be run in resource-constrained environments.

## Context
As the scope of large language model capabilities expands, a growing area of research is using LLMs to characterize themselves. Because many preexisting NLP benchmarks have been shown to be trivial for state-of-the-art models, there has also been interesting work showing that LLMs can be used to create more challenging tasks to test ever more powerful models.

At the same time methods like quantization and knowledge distillation are being used to effectively shrink language models and run them on more modest hardware. The Kaggle environment provides a unique lens to study this as submissions are subject to both GPU and time limits.

The dataset for this challenge was generated by giving gpt3.5 snippets of text on a range of scientific topics pulled from wikipedia, and asking it to write a multiple choice question (with a known answer), then filtering out easy questions.

Right now we estimate that the largest models run on Kaggle are around 10 billion parameters, whereas gpt3.5 clocks in at 175 billion parameters. If a question-answering model can ace a test written by a question-writing model more than 10 times its size, this would be a genuinely interesting result; on the other hand if a larger model can effectively stump a smaller one, this has compelling implications on the ability of LLMs to benchmark and test themselves.

## Türkçe
## Yarışmanın Amacı
OpenBookQA veri setinden ilham alan bu yarışma, katılımcıları Büyük Dil Modeli tarafından yazılmış bilime dayalı zor soruları yanıtlamaya zorlar.

Çalışmanız, araştırmacıların LLM'lerin kendilerini test etme yeteneklerini ve kısıtlı kaynaklara sahip ortamlarda çalıştırılabilecek LLM'lerin potansiyelini daha iyi anlamalarına yardımcı olacaktır.

## Bağlam
Büyük dil modeli yeteneklerinin kapsamı genişledikçe, büyüyen bir araştırma alanı kendilerini karakterize etmek için LLM'leri kullanıyor. Önceden var olan birçok NLP kıyaslamasının son teknoloji modeller için önemsiz olduğu gösterildiğinden, LLM'lerin daha güçlü modelleri test etmek için daha zorlu görevler oluşturmak için kullanılabileceğini gösteren ilginç çalışmalar da var.

Aynı zamanda, niceleme ve bilgi damıtma gibi yöntemler, dil modellerini etkili bir şekilde küçültmek ve daha mütevazı bir donanımda çalıştırmak için kullanılıyor. Gönderimler hem GPU'ya hem de zaman sınırlarına tabi olduğundan, Kaggle ortamı bunu incelemek için benzersiz bir mercek sağlar.

Bu meydan okuma için veri kümesi, wikipedia'dan alınan bir dizi bilimsel konu hakkında gpt3.5 metin parçacıkları verilerek ve ondan çoktan seçmeli bir soru (bilinen bir yanıtla) yazmasını isteyerek ve ardından kolay soruları filtreleyerek oluşturuldu.

Şu anda Kaggle üzerinde çalışan en büyük modellerin yaklaşık 10 milyar parametre olduğunu, oysa gpt3.5'in 175 milyar parametrede çalıştığını tahmin ediyoruz. Eğer bir soru-cevap modeli, bir soru-yazılı model tarafından yazılan bir testte kendi boyutunun 10 katından daha fazla başarılı olabiliyorsa, bu gerçekten ilginç bir sonuç olacaktır; Öte yandan, daha büyük bir model daha küçük bir modeli etkili bir şekilde geride bırakabiliyorsa, bunun LLM'lerin kendilerini kıyaslama ve test etme becerileri üzerinde zorlayıcı etkileri vardır.