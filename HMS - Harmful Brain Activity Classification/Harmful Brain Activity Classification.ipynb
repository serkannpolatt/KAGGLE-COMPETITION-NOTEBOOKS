{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98109ab",
   "metadata": {
    "papermill": {
     "duration": 0.015597,
     "end_time": "2024-03-16T18:09:14.809410",
     "exception": false,
     "start_time": "2024-03-16T18:09:14.793813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notes - This notebook is an extension of the discussion forund here: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/484124\n",
    "\n",
    "##### This aids to show th benefits of diversity of different modeling. In this notebook we see LB of 0.41, 0.37, and 0.36 yet when we average them we see far better scores of 0.31. However this does come with its warnings. This notebook uses a combonation of 2 stage and 1 stage which \"could\" be dramatically overfitting the LB depending on the outcome of the distribution of voters in the test set. I would personally suggest a deep review of the methods used in this notebook before you opt to use any strategies from it. Please reference the many warnings about this in the discussions for more details.\n",
    "\n",
    "#### Lastly, please do check out the hard work of those who have created these datasets and notebooks in the first place! Or who combined them in @Majiaqi111 . A high LB score does not always mean a good solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1e7e5",
   "metadata": {
    "papermill": {
     "duration": 0.01467,
     "end_time": "2024-03-16T18:09:14.839307",
     "exception": false,
     "start_time": "2024-03-16T18:09:14.824637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1 - @andreasbis 0.41 \n",
    "https://www.kaggle.com/code/andreasbis/hms-inference-lb-0-41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f53fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:14.870047Z",
     "iopub.status.busy": "2024-03-16T18:09:14.869731Z",
     "iopub.status.idle": "2024-03-16T18:09:22.408888Z",
     "shell.execute_reply": "2024-03-16T18:09:22.407739Z"
    },
    "papermill": {
     "duration": 7.557228,
     "end_time": "2024-03-16T18:09:22.411243",
     "exception": false,
     "start_time": "2024-03-16T18:09:14.854015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing essential libraries\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision for image processing and augmentation\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Suppressing minor warnings to keep the output clean\n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00b5a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:22.448569Z",
     "iopub.status.busy": "2024-03-16T18:09:22.447632Z",
     "iopub.status.idle": "2024-03-16T18:09:22.458792Z",
     "shell.execute_reply": "2024-03-16T18:09:22.458008Z"
    },
    "papermill": {
     "duration": 0.032037,
     "end_time": "2024-03-16T18:09:22.460818",
     "exception": false,
     "start_time": "2024-03-16T18:09:22.428781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed=42\n",
    "    image_transform=transforms.Resize((512, 512))\n",
    "    num_folds=5\n",
    "    \n",
    "# Set the seed for reproducibility across multiple libraries\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268b7b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:22.496885Z",
     "iopub.status.busy": "2024-03-16T18:09:22.496510Z",
     "iopub.status.idle": "2024-03-16T18:09:32.741092Z",
     "shell.execute_reply": "2024-03-16T18:09:32.740187Z"
    },
    "papermill": {
     "duration": 10.265316,
     "end_time": "2024-03-16T18:09:32.743236",
     "exception": false,
     "start_time": "2024-03-16T18:09:22.477920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and store the trained models for each fold into a list\n",
    "models = []\n",
    "\n",
    "# Load ResNet34d\n",
    "for i in range(Config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_resnet = timm.create_model('resnet34d', pretrained=False, num_classes=6, in_chans=1)\n",
    "    \n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_resnet.load_state_dict(torch.load(f'/kaggle/input/hms-train-resnet34d/resnet34d_fold{i}.pth', map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_resnet)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()\n",
    "\n",
    "# Load EfficientNetB0\n",
    "for j in range(Config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_effnet_b0 = timm.create_model('efficientnet_b0', pretrained=False, num_classes=6, in_chans=1)\n",
    "    \n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_effnet_b0.load_state_dict(torch.load(f'/kaggle/input/hms-train-efficientnetb0/efficientnet_b0_fold{j}.pth', map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_effnet_b0)\n",
    "    \n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()\n",
    "    \n",
    "# Load EfficientNetB1\n",
    "for k in range(Config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n",
    "    \n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/hms-train-efficientnetb1/efficientnet_b1_fold{k}.pth', map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_effnet_b1)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2077e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:32.775816Z",
     "iopub.status.busy": "2024-03-16T18:09:32.775519Z",
     "iopub.status.idle": "2024-03-16T18:09:32.989723Z",
     "shell.execute_reply": "2024-03-16T18:09:32.988664Z"
    },
    "papermill": {
     "duration": 0.232782,
     "end_time": "2024-03-16T18:09:32.991885",
     "exception": false,
     "start_time": "2024-03-16T18:09:32.759103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>853520</td>\n",
       "      <td>6885</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.166667  0.166667  0.166667   0.166667   0.166667   \n",
       "\n",
       "   other_vote  spectrogram_id  patient_id  \\\n",
       "0    0.166667          853520        6885   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/hms-harmful-brain-activity-class...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data and sample submission dataframe\n",
    "test_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n",
    "\n",
    "# Merge the submission dataframe with the test data on EEG IDs\n",
    "submission = submission.merge(test_df, on='eeg_id', how='left')\n",
    "\n",
    "# Generate file paths for each spectrogram based on the EEG data in the submission dataframe\n",
    "submission['path'] = submission['spectrogram_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/{x}.parquet\")\n",
    "\n",
    "# Display the first few rows of the submission dataframe\n",
    "display(submission.head())\n",
    "\n",
    "# Reclaim memory no longer in use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c998ee9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:33.027812Z",
     "iopub.status.busy": "2024-03-16T18:09:33.027463Z",
     "iopub.status.idle": "2024-03-16T18:09:36.509619Z",
     "shell.execute_reply": "2024-03-16T18:09:36.508606Z"
    },
    "papermill": {
     "duration": 3.502651,
     "end_time": "2024-03-16T18:09:36.511676",
     "exception": false,
     "start_time": "2024-03-16T18:09:33.009025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the weights for each model\n",
    "weight_resnet34d = 0.26\n",
    "weight_effnetb0 = 0.48\n",
    "weight_effnetb1 = 0.26\n",
    "\n",
    "# Get file paths for test spectrograms\n",
    "paths = submission['path'].values\n",
    "test_preds = []\n",
    "\n",
    "# Generate predictions for each spectrogram using all models\n",
    "for path in paths:\n",
    "    eps = 1e-6\n",
    "    # Read and preprocess spectrogram data\n",
    "    data = pd.read_parquet(path)\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "    \n",
    "    # Normalize the data\n",
    "    data_mean = data.mean(axis=(0, 1))\n",
    "    data_std = data.std(axis=(0, 1))\n",
    "    data = (data - data_mean) / (data_std + eps)\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "    data = Config.image_transform(data_tensor)\n",
    "\n",
    "    test_pred = []\n",
    "    \n",
    "    # Generate predictions using all models\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(model(data.unsqueeze(0)))[0]\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        test_pred.append(pred)\n",
    "        \n",
    "    # Combine predictions from all models using weighted voting\n",
    "    weighted_pred = weight_resnet34d * np.mean(test_pred[:Config.num_folds], axis=0) + \\\n",
    "                     weight_effnetb0 * np.mean(test_pred[Config.num_folds:2*Config.num_folds], axis=0) + \\\n",
    "                     weight_effnetb1 * np.mean(test_pred[2*Config.num_folds:], axis=0)\n",
    "    \n",
    "    test_preds.append(weighted_pred)\n",
    "\n",
    "# Convert the list of predictions to a NumPy array for further processing\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "# Reclaim memory no longer in use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e26cdf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:36.547996Z",
     "iopub.status.busy": "2024-03-16T18:09:36.547656Z",
     "iopub.status.idle": "2024-03-16T18:09:36.728390Z",
     "shell.execute_reply": "2024-03-16T18:09:36.727063Z"
    },
    "papermill": {
     "duration": 0.200663,
     "end_time": "2024-03-16T18:09:36.731142",
     "exception": false,
     "start_time": "2024-03-16T18:09:36.530479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.034403</td>\n",
       "      <td>0.103879</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.371507</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>0.478578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.034403  0.103879  0.000818   0.371507   0.010815   \n",
       "\n",
       "   other_vote  \n",
       "0    0.478578  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sample submission file and update it with model predictions for each label\n",
    "sub1 = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n",
    "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "# Assign model predictions to respective columns in the submission DataFrame\n",
    "for i in range(len(labels)):\n",
    "    sub1[f'{labels[i]}_vote'] = test_preds[:, i]\n",
    "\n",
    "display(sub1.head())\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e353ed58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:36.777084Z",
     "iopub.status.busy": "2024-03-16T18:09:36.776423Z",
     "iopub.status.idle": "2024-03-16T18:09:36.783753Z",
     "shell.execute_reply": "2024-03-16T18:09:36.782782Z"
    },
    "papermill": {
     "duration": 0.030993,
     "end_time": "2024-03-16T18:09:36.786462",
     "exception": false,
     "start_time": "2024-03-16T18:09:36.755469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub1.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39bfd3",
   "metadata": {
    "papermill": {
     "duration": 0.017075,
     "end_time": "2024-03-16T18:09:36.823249",
     "exception": false,
     "start_time": "2024-03-16T18:09:36.806174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2 - @minhsienweng 0.37\n",
    "https://www.kaggle.com/code/minhsienweng/infer-features-head-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad2897f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:36.902004Z",
     "iopub.status.busy": "2024-03-16T18:09:36.901650Z",
     "iopub.status.idle": "2024-03-16T18:09:52.117987Z",
     "shell.execute_reply": "2024-03-16T18:09:52.117114Z"
    },
    "papermill": {
     "duration": 15.237688,
     "end_time": "2024-03-16T18:09:52.120717",
     "exception": false,
     "start_time": "2024-03-16T18:09:36.883029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, random, sys\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import albumentations as albu\n",
    "from scipy.signal import butter, lfilter\n",
    "import librosa\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7add909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:52.156442Z",
     "iopub.status.busy": "2024-03-16T18:09:52.155841Z",
     "iopub.status.idle": "2024-03-16T18:09:52.160738Z",
     "shell.execute_reply": "2024-03-16T18:09:52.159700Z"
    },
    "papermill": {
     "duration": 0.024748,
     "end_time": "2024-03-16T18:09:52.162764",
     "exception": false,
     "start_time": "2024-03-16T18:09:52.138016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models'\n",
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76cf349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:52.196279Z",
     "iopub.status.busy": "2024-03-16T18:09:52.196009Z",
     "iopub.status.idle": "2024-03-16T18:09:52.201084Z",
     "shell.execute_reply": "2024-03-16T18:09:52.200139Z"
    },
    "papermill": {
     "duration": 0.02419,
     "end_time": "2024-03-16T18:09:52.203178",
     "exception": false,
     "start_time": "2024-03-16T18:09:52.178988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all \n",
    "def seed_everything(seed=42):\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fccd483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:52.236596Z",
     "iopub.status.busy": "2024-03-16T18:09:52.236274Z",
     "iopub.status.idle": "2024-03-16T18:09:52.240866Z",
     "shell.execute_reply": "2024-03-16T18:09:52.240037Z"
    },
    "papermill": {
     "duration": 0.023905,
     "end_time": "2024-03-16T18:09:52.242890",
     "exception": false,
     "start_time": "2024-03-16T18:09:52.218985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "def clear_memory():\n",
    "    libc.malloc_trim(0)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1239a64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:52.278151Z",
     "iopub.status.busy": "2024-03-16T18:09:52.277451Z",
     "iopub.status.idle": "2024-03-16T18:09:53.316582Z",
     "shell.execute_reply": "2024-03-16T18:09:53.315480Z"
    },
    "papermill": {
     "duration": 1.059483,
     "end_time": "2024-03-16T18:09:53.318882",
     "exception": false,
     "start_time": "2024-03-16T18:09:52.259399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "# USE SINGLE GPU, MULTIPLE GPUS \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# WE USE MIXED PRECISION\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "if len(gpus)>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3783844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.354514Z",
     "iopub.status.busy": "2024-03-16T18:09:53.354175Z",
     "iopub.status.idle": "2024-03-16T18:09:53.369349Z",
     "shell.execute_reply": "2024-03-16T18:09:53.368610Z"
    },
    "papermill": {
     "duration": 0.035464,
     "end_time": "2024-03-16T18:09:53.371328",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.335864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod \n",
    "  \n",
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "USE_PROCESSED = True # Use processed downsampled Raw EEG \n",
    "    \n",
    "class BaseDataGenerator():\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs, eeg_specs, raw_eegs, augment, mode, data_type): \n",
    "        self.data = data\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.raw_eegs = raw_eegs\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        if self.augment: X = self.augmentation(X)\n",
    "        return X, y\n",
    "    \n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()\n",
    "                \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode=='train': \n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Abstract method generate data based on the trained data type\n",
    "    @abstractmethod\n",
    "    def data_generation(self, index):\n",
    "        pass\n",
    "        \n",
    "    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "        return filtered_data\n",
    "    \n",
    "    def resize(self, img,size):\n",
    "        composition = albu.Compose([\n",
    "                albu.Resize(size[0],size[1])\n",
    "            ])\n",
    "        return composition(image=img)['image']\n",
    "            \n",
    "    def augmentation(self, img):\n",
    "        composition = albu.Compose([\n",
    "                albu.HorizontalFlip(p=0.4)\n",
    "            ])\n",
    "        return composition(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce52287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.405965Z",
     "iopub.status.busy": "2024-03-16T18:09:53.405683Z",
     "iopub.status.idle": "2024-03-16T18:09:53.455106Z",
     "shell.execute_reply": "2024-03-16T18:09:53.454385Z"
    },
    "papermill": {
     "duration": 0.068881,
     "end_time": "2024-03-16T18:09:53.456961",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.388080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementation class generates the data based on the data_type \n",
    "class DataGenerator(BaseDataGenerator):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs, eeg_specs, raw_eegs, augment, \n",
    "                 mode, data_type): \n",
    "        super().__init__(data, specs, eeg_specs, raw_eegs, augment, mode, data_type)\n",
    "    \n",
    "    def data_generation(self, index):\n",
    "        if self.data_type == 'KE':\n",
    "            X,y = self.generate_all_specs(index)\n",
    "        elif self.data_type == 'E' or self.data_type == 'K':\n",
    "            X,y = self.generate_specs(index)\n",
    "        elif self.data_type == 'R':\n",
    "            X,y = self.generate_raw(index)\n",
    "        elif self.data_type in ['ER','KR']:\n",
    "            X1,y = self.generate_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        elif self.data_type == 'KER':\n",
    "            X1,y = self.generate_all_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        return X,y\n",
    "    \n",
    "    def generate_all_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "        \n",
    "        eeg = self.eeg_specs[row.eeg_id]\n",
    "        spec = self.specs[row.spec_id]\n",
    "        \n",
    "        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "        img = np.stack(imgs,axis=-1)\n",
    "        # LOG TRANSFORM SPECTROGRAM\n",
    "        img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "        img = np.log(img)\n",
    "            \n",
    "        # STANDARDIZE PER IMAGE\n",
    "        img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n",
    "        \n",
    "        # EEG\n",
    "        img = eeg\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n",
    "\n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "            \n",
    "        if self.data_type in ['E','ER']:\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "        elif self.data_type in ['K','KR']:\n",
    "            spec = self.specs[row.spec_id]\n",
    "            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "            img = np.stack(imgs,axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "            img = np.log(img)\n",
    "            \n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_raw(self,index):\n",
    "        if USE_PROCESSED and self.mode!='test':\n",
    "            X = np.zeros((2_000,8),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            row = self.data.iloc[index]\n",
    "            X = self.raw_eegs[row.eeg_id]\n",
    "            y[:] = row[TARGETS]\n",
    "            return X,y\n",
    "        \n",
    "        X = np.zeros((10_000,8),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        eeg = self.raw_eegs[row.eeg_id]\n",
    "            \n",
    "        # FEATURE ENGINEER\n",
    "        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        # STANDARDIZE\n",
    "        X = np.clip(X,-1024,1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "            \n",
    "        # BUTTER LOW-PASS FILTER\n",
    "        X = self.butter_lowpass_filter(X)\n",
    "        # Downsample\n",
    "        X = X[::5,:]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "                \n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcd886f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.492035Z",
     "iopub.status.busy": "2024-03-16T18:09:53.491731Z",
     "iopub.status.idle": "2024-03-16T18:09:53.499969Z",
     "shell.execute_reply": "2024-03-16T18:09:53.499123Z"
    },
    "papermill": {
     "duration": 0.028051,
     "end_time": "2024-03-16T18:09:53.501940",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.473889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(data, mode, data_type, specs, eeg_specs, raw_eegs, augment=False,\n",
    "                   batch_size=8):    \n",
    "    if data_type in ['K','E','KE', 'K+E']: \n",
    "        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32), \n",
    "               tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\n",
    "    elif data_type in ['R']:\n",
    "        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\n",
    "\n",
    "    output_signature = (inp, tf.TensorSpec(shape=(6,), dtype=tf.float32))\n",
    "    \n",
    "    \n",
    "    # Create the data generator\n",
    "    gen = DataGenerator(data, specs, eeg_specs, raw_eegs, augment, mode, data_type)\n",
    "    # Create the dataset from data generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator=gen,\n",
    "                                             output_signature=output_signature).batch(batch_size * strategy.num_replicas_in_sync)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bfbebeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.537089Z",
     "iopub.status.busy": "2024-03-16T18:09:53.536827Z",
     "iopub.status.idle": "2024-03-16T18:09:53.549715Z",
     "shell.execute_reply": "2024-03-16T18:09:53.548858Z"
    },
    "papermill": {
     "duration": 0.033644,
     "end_time": "2024-03-16T18:09:53.551852",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.518208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectrogram_from_eeg(parquet_path):    \n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg)-10_000)//2\n",
    "    eeg = eeg.iloc[middle:middle+10_000]\n",
    "    \n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((100,300,4) ,dtype='float32')\n",
    "\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "        \n",
    "        for kk in range(4):\n",
    "            # FILL NANS\n",
    "            x1 = eeg[COLS[kk]].values\n",
    "            x2 = eeg[COLS[kk+1]].values\n",
    "            m = np.nanmean(x1)\n",
    "            if np.isnan(x1).mean()<1: \n",
    "                x1 = np.nan_to_num(x1,nan=m)\n",
    "            else: \n",
    "                x1[:] = 0\n",
    "            m = np.nanmean(x2)\n",
    "            if np.isnan(x2).mean()<1: \n",
    "                x2 = np.nan_to_num(x2,nan=m)\n",
    "            else: \n",
    "                x2[:] = 0\n",
    "                \n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = x1 - x2\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n",
    "                                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n",
    "            \n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1]//30)*30\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "            img[:,:,k] += mel_spec_db\n",
    "                \n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:,:,k] /= 4.0\n",
    "    return img\n",
    "# Read EEG from par files\n",
    "def eeg_from_parquet(parquet_path):\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-10_000)//2\n",
    "    eeg = eeg.iloc[offset:offset+10_000]\n",
    "    data = np.zeros((10_000,len(FEATS2)))\n",
    "    for j,col in enumerate(FEATS2):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        data[:,j] = x\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33ddbb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.587542Z",
     "iopub.status.busy": "2024-03-16T18:09:53.587213Z",
     "iopub.status.idle": "2024-03-16T18:09:53.594382Z",
     "shell.execute_reply": "2024-03-16T18:09:53.593566Z"
    },
    "papermill": {
     "duration": 0.027304,
     "end_time": "2024-03-16T18:09:53.596594",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.569290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_spec_model(hybrid=False):\n",
    "    LOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'\n",
    "    base_model = load_model(f'{LOAD_BACKBONE_FROM}')\n",
    "    \n",
    "    inp = tf.keras.layers.Input((512,512,3))        \n",
    "    x = base_model(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if not hybrid:\n",
    "        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    # Create the model\n",
    "    model_spec = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model_spec.compile(loss=loss, optimizer=opt)\n",
    "    return model_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae75ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.632265Z",
     "iopub.status.busy": "2024-03-16T18:09:53.631965Z",
     "iopub.status.idle": "2024-03-16T18:09:53.650127Z",
     "shell.execute_reply": "2024-03-16T18:09:53.649221Z"
    },
    "papermill": {
     "duration": 0.038656,
     "end_time": "2024-03-16T18:09:53.652284",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.613628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters = filters,\n",
    "               kernel_size = 1,\n",
    "               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x\n",
    "        \n",
    "def build_wave_model(hybrid=False):\n",
    "    # INPUT \n",
    "    inp = tf.keras.Input(shape=(2_000,8))\n",
    "\n",
    "    ############\n",
    "    # FEATURE EXTRACTION SUB MODEL\n",
    "    inp2 = tf.keras.Input(shape=(2_000,1))\n",
    "    x = wave_block(inp2, 8, 4, 6)\n",
    "    x = wave_block(x, 16, 4, 6)\n",
    "    x = wave_block(x, 32, 4, 6)\n",
    "    x = wave_block(x, 64, 4, 6)\n",
    "    base_model = tf.keras.Model(inputs=inp2, outputs=x)\n",
    "    ###########\n",
    "\n",
    "    # LEFT TEMPORAL CHAIN\n",
    "    x1 = base_model(inp[:,:,0:1])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,1:2])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z1 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # LEFT PARASAGITTAL CHAIN\n",
    "    x1 = base_model(inp[:,:,2:3])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,3:4])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z2 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # RIGHT PARASAGITTAL CHAIN\n",
    "    x1 = base_model(inp[:,:,4:5])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,5:6])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z3 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # RIGHT TEMPORAL CHAIN\n",
    "    x1 = base_model(inp[:,:,6:7])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,7:8])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z4 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # COMBINE CHAINS\n",
    "    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n",
    "    if not hybrid:\n",
    "        y = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "        y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n",
    "\n",
    "    # COMPILE MODEL\n",
    "    model_wave = tf.keras.Model(inputs=inp, outputs=y)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model_wave.compile(loss=loss, optimizer = opt)\n",
    "    return model_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97afc3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.685842Z",
     "iopub.status.busy": "2024-03-16T18:09:53.685558Z",
     "iopub.status.idle": "2024-03-16T18:09:53.691853Z",
     "shell.execute_reply": "2024-03-16T18:09:53.691075Z"
    },
    "papermill": {
     "duration": 0.025416,
     "end_time": "2024-03-16T18:09:53.694217",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.668801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_hyrbid_model():\n",
    "    model_spec = build_spec_model(hybrid=True)\n",
    "    model_wave = build_wave_model(hybrid=True)\n",
    "    inputs = [model_spec.input, model_wave.input]\n",
    "    x = [model_spec.output, model_wave.output]\n",
    "    x = tf.keras.layers.Concatenate()(x)\n",
    "    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "\n",
    "    # COMPILE MODEL\n",
    "    model_hybrid = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model_hybrid.compile(loss=loss, optimizer = opt)\n",
    "    return model_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "340d8ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:09:53.729088Z",
     "iopub.status.busy": "2024-03-16T18:09:53.728822Z",
     "iopub.status.idle": "2024-03-16T18:10:22.077160Z",
     "shell.execute_reply": "2024-03-16T18:10:22.076237Z"
    },
    "papermill": {
     "duration": 28.367914,
     "end_time": "2024-03-16T18:10:22.079689",
     "exception": false,
     "start_time": "2024-03-16T18:09:53.711775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_spec = build_spec_model(hybrid=False)\n",
    "model_wave = build_wave_model(hybrid=False)\n",
    "model_hybrid = build_hyrbid_model()\n",
    "# print(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea0d0205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:22.116928Z",
     "iopub.status.busy": "2024-03-16T18:10:22.116612Z",
     "iopub.status.idle": "2024-03-16T18:10:22.121724Z",
     "shell.execute_reply": "2024-03-16T18:10:22.120787Z"
    },
    "papermill": {
     "duration": 0.026173,
     "end_time": "2024-03-16T18:10:22.123698",
     "exception": false,
     "start_time": "2024-03-16T18:10:22.097525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERS ={\n",
    "    'K': 43, # Kaggle spectrogram\n",
    "    'E': 42, # EEG spectrogram \n",
    "    'R': 37, # Raw EEG \n",
    "    'KE': 47, # Kaggle + EEG spectrogram\n",
    "    'KR': 48, # Kaggle spectrogram + Raw EEG \n",
    "    'ER': 49, # EEG spectrogram + Raw EEG  \n",
    "    'KER': 50, # Kaggle + EGG spectrogram + Raw EEG \n",
    "    'K+E': 51, # Kaggle + EEG spectrogram + Data augumentation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5e74db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:22.160638Z",
     "iopub.status.busy": "2024-03-16T18:10:22.159886Z",
     "iopub.status.idle": "2024-03-16T18:10:22.177595Z",
     "shell.execute_reply": "2024-03-16T18:10:22.176620Z"
    },
    "papermill": {
     "duration": 0.038743,
     "end_time": "2024-03-16T18:10:22.179664",
     "exception": false,
     "start_time": "2024-03-16T18:10:22.140921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "\n",
    "# Load training data\n",
    "def add_kl(data):\n",
    "    labels = data[TARGETS].values + 1e-5 \n",
    "    data['kl'] = tf.keras.losses.KLDivergence(reduction='none')(np.array([[1/6]*6]*len(data)), labels)\n",
    "    return data\n",
    "    \n",
    "def load_train_data():\n",
    "    # Load training features\n",
    "    train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
    "    META = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\n",
    "    train = train.groupby('eeg_id')[META+TARGETS].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \n",
    "    train[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\n",
    "    train.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\n",
    "    train = add_kl(train)\n",
    "    # display(train.head(3))\n",
    "    # Read all spectrograms\n",
    "    train_specs = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()\n",
    "    # Read all EEG Spectrograms\n",
    "    train_eegs = np.load('/kaggle/input/eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n",
    "    # Read all raw EGG signals\n",
    "    train_raw_eegs = np.load('/kaggle/input/hms-eeg/eegs_processed.npy',allow_pickle=True).item()\n",
    "    return train, train_specs, train_eegs, train_raw_eegs\n",
    "\n",
    "# Compute the score using KLDivergence \n",
    "# KL measures how much prediction prob distribution differs from actual prob distribution\n",
    "def compute_score(y_true, y_pred):\n",
    "    kl = tf.keras.metrics.KLDivergence()\n",
    "    return kl(y_true, y_pred)\n",
    "\n",
    "# Submission ON TEST with an individual\n",
    "def preds_with_a_model(data_type):\n",
    "    VER=VERS[data_type]\n",
    "    train, train_specs, train_eegs, train_raw_eegs = load_train_data()\n",
    "    # Make the predictions with 5 fold models\n",
    "    all_oof = []\n",
    "    all_true = []\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    for i, (_, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):   \n",
    "        print(f'### Fold {i+1}')\n",
    "        true_values = train.iloc[valid_index][TARGETS].values  \n",
    "        all_true.append(true_values)\n",
    "        # Valid dataset\n",
    "        val_df = train.iloc[valid_index]\n",
    "        val_dataset = create_dataset(val_df, mode='train', data_type=data_type,\n",
    "                                     specs=train_specs, eeg_specs=train_eegs, \n",
    "                                     raw_eegs=train_raw_eegs)\n",
    "        print(f'valid size {len(valid_index)}')\n",
    "        model = None\n",
    "        if data_type in ['K','E','KE']:\n",
    "            model = model_spec\n",
    "        elif data_type in ['R']:\n",
    "            model = model_wave\n",
    "        elif data_type in ['KR','ER','KER']:\n",
    "            model = model_hybrid\n",
    "        # EEG's, Kaggle's spectrograms and Raw model\n",
    "        model.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        oof = model.predict(val_dataset, verbose=1)\n",
    "        print(f\"oof shape = {np.array(oof).shape}\")\n",
    "        all_oof.append(oof)           \n",
    "        del val_df, val_dataset\n",
    "        clear_memory()\n",
    "\n",
    "    # Compute the score with predictions and actual labels\n",
    "    all_oof = np.concatenate(all_oof)\n",
    "    all_true = np.concatenate(all_true)\n",
    "    print(f\"all_oof shape = {all_oof.shape} and all_true shape = {all_true.shape}\")\n",
    "    print(f'CV KL SCORE of {data_type} model: {compute_score(all_true,all_oof)}')\n",
    "    del train, train_specs, train_eegs, train_raw_eegs\n",
    "    clear_memory()\n",
    "    \n",
    "# # Compute the cross validation score for a model\n",
    "# preds_with_a_model(data_type='KE')\n",
    "# sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdce887e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:22.214967Z",
     "iopub.status.busy": "2024-03-16T18:10:22.214666Z",
     "iopub.status.idle": "2024-03-16T18:10:22.228249Z",
     "shell.execute_reply": "2024-03-16T18:10:22.227333Z"
    },
    "papermill": {
     "duration": 0.033537,
     "end_time": "2024-03-16T18:10:22.230358",
     "exception": false,
     "start_time": "2024-03-16T18:10:22.196821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_id      eeg_id  patient_id\n",
       "0   853520  3911565283        6885"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load testing features\n",
    "test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "# Rename\n",
    "test = test.rename({'spectrogram_id':'spec_id'},axis=1)\n",
    "print('Test shape',test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16794385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:22.266319Z",
     "iopub.status.busy": "2024-03-16T18:10:22.266048Z",
     "iopub.status.idle": "2024-03-16T18:10:22.301278Z",
     "shell.execute_reply": "2024-03-16T18:10:22.300294Z"
    },
    "papermill": {
     "duration": 0.055395,
     "end_time": "2024-03-16T18:10:22.303563",
     "exception": false,
     "start_time": "2024-03-16T18:10:22.248168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 test spectrogram parquets\n"
     ]
    }
   ],
   "source": [
    "# Read all spectrograms\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\n",
    "files = os.listdir(PATH)\n",
    "print(f'There are {len(files)} test spectrogram parquets')\n",
    "test_specs = {}\n",
    "for i,f in enumerate(files):\n",
    "    tmp = pd.read_parquet(f'{PATH}/{f}')\n",
    "    name = int(f.split('.')[0])\n",
    "    test_specs[name] = tmp.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8762ea58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:22.338983Z",
     "iopub.status.busy": "2024-03-16T18:10:22.338290Z",
     "iopub.status.idle": "2024-03-16T18:10:33.226787Z",
     "shell.execute_reply": "2024-03-16T18:10:33.225363Z"
    },
    "papermill": {
     "duration": 10.910615,
     "end_time": "2024-03-16T18:10:33.230620",
     "exception": false,
     "start_time": "2024-03-16T18:10:22.320005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Test EEG to Spectrograms...\n"
     ]
    }
   ],
   "source": [
    "# Read all EEG Spectrograms\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "DISPLAY = 0\n",
    "EEG_IDS = test.eeg_id.unique()\n",
    "test_eeg_specs = {}\n",
    "print('Converting Test EEG to Spectrograms...')\n",
    "for i,eeg_id in enumerate(EEG_IDS):\n",
    "    # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "    test_eeg_specs[eeg_id] = spectrogram_from_eeg(f'{PATH}/{eeg_id}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45bfa388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:33.308351Z",
     "iopub.status.busy": "2024-03-16T18:10:33.306649Z",
     "iopub.status.idle": "2024-03-16T18:10:33.343158Z",
     "shell.execute_reply": "2024-03-16T18:10:33.341762Z"
    },
    "papermill": {
     "duration": 0.079086,
     "end_time": "2024-03-16T18:10:33.347189",
     "exception": false,
     "start_time": "2024-03-16T18:10:33.268103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Test EEG parquets...\n"
     ]
    }
   ],
   "source": [
    "# Read all RAW EEG Signals\n",
    "test_raw_eegs = {}\n",
    "EEG_IDS = test.eeg_id.unique()\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "print('Processing Test EEG parquets...')\n",
    "for i,eeg_id in enumerate(EEG_IDS):\n",
    "    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n",
    "    test_raw_eegs[eeg_id] = eeg_from_parquet(f'{PATH}/{eeg_id}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7aced90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:33.389975Z",
     "iopub.status.busy": "2024-03-16T18:10:33.389687Z",
     "iopub.status.idle": "2024-03-16T18:10:33.590947Z",
     "shell.execute_reply": "2024-03-16T18:10:33.590107Z"
    },
    "papermill": {
     "duration": 0.222448,
     "end_time": "2024-03-16T18:10:33.593548",
     "exception": false,
     "start_time": "2024-03-16T18:10:33.371100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'specs':test_specs, 'eeg_specs':test_eeg_specs, 'raw_eegs':test_raw_eegs}\n",
    "test_datasets ={\n",
    "    'K': create_dataset(test, data_type='K', mode='test', **params),\n",
    "    'E': create_dataset(test, data_type='E', mode='test', **params),\n",
    "    'R': create_dataset(test, data_type='R', mode='test', **params),\n",
    "    'KE': create_dataset(test, data_type='KE', mode='test', **params),\n",
    "    'KR': create_dataset(test, data_type='KR', mode='test', **params),\n",
    "    'ER': create_dataset(test, data_type='ER', mode='test', **params),\n",
    "    'KER': create_dataset(test, data_type='KER', mode='test', **params),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a8db145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:33.633542Z",
     "iopub.status.busy": "2024-03-16T18:10:33.632743Z",
     "iopub.status.idle": "2024-03-16T18:10:52.633373Z",
     "shell.execute_reply": "2024-03-16T18:10:52.632255Z"
    },
    "papermill": {
     "duration": 19.022615,
     "end_time": "2024-03-16T18:10:52.635489",
     "exception": false,
     "start_time": "2024-03-16T18:10:33.612874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Fold 2\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Fold 3\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Fold 4\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Fold 5\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Test preds shape (1, 6)\n"
     ]
    }
   ],
   "source": [
    "LBs = [0.41,0.39,0.41,0.37,0.39,0.38,0.36] # K|E|R|KE|KR|ER|KER for weighted ensemble we use LBs of each model\n",
    "\n",
    "def make_preds(i, data_type):\n",
    "    VER = VERS[data_type]\n",
    "    test_dataset = test_datasets[data_type]\n",
    "    model_preds = None\n",
    "    if data_type in ['K','E','KE']:\n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        model_preds = model_spec.predict(test_dataset, verbose=1)\n",
    "    elif data_type in ['R']:\n",
    "        model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        model_preds = model_wave.predict(test_dataset, verbose=1)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        model_preds = model_hybrid.predict(test_dataset, verbose=1)\n",
    "    clear_memory()\n",
    "    return model_preds\n",
    "\n",
    "# Submission ON TEST with ensemble\n",
    "def preds_with_ensemble():\n",
    "    preds = []\n",
    "    # LB SCORE WEIGHTS FOR EACH MODEL\n",
    "    lbs = 1 - np.array(LBs)\n",
    "    weights = lbs/lbs.sum()\n",
    "    for i in range(5):\n",
    "        print(f'Fold {i+1}')\n",
    "        # 'KE' model (Kaggle and EEG spectrogram)\n",
    "        preds.append(make_preds(i, data_type='KE'))\n",
    "        \n",
    "        ## 'K' model (Kaggle spectrograms)\n",
    "#         model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_K_{VER_K}_{i}.weights.h5')\n",
    "#         pred_K = model_spec.predict(test_dataset_K, verbose=1)\n",
    "        ## EEG's spectrogram model\n",
    "#         model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_E_{VER_E}_{i}.weights.h5')\n",
    "#         pred_E = model_spec.predict(test_dataset_E, verbose=1)\n",
    "        # EEG Raw wavenet model\n",
    "#         model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_R_{VER_R}_{i}.weights.h5')\n",
    "#         pred_R = model_wave.predict(test_dataset_R, verbose=1)\n",
    "       \n",
    "#         # Kaggle's spectrogram and Raw model\n",
    "#         model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KR_{VER_KR}_{i}.weights.h5')\n",
    "#         pred_KR = model_hybrid.predict(test_dataset_KR, verbose=1)\n",
    "#         # EEG's spectrogram and Raw model\n",
    "#         model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_ER_{VER_ER}_{i}.weights.h5')\n",
    "#         pred_ER = model_hybrid.predict(test_dataset_ER, verbose=1)\n",
    "#         # EEG's, Kaggle's spectrograms and Raw model\n",
    "#         model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5')\n",
    "#         pred_KER = model_hybrid.predict(test_dataset_KER, verbose=1)\n",
    "        # Combine the predictions from all the model with different weights \n",
    "#         pred = np.array([pred_K,pred_E,pred_R,pred_KE,pred_KR,pred_ER,pred_KER])\n",
    "#         pred = np.average(pred,axis=0,weights=weights)\n",
    "        \n",
    "#         preds.append(pred)\n",
    "    # Average the prediction of all five fold models\n",
    "    avg_pred = np.mean(preds, axis=0)\n",
    "    clear_memory()\n",
    "    return avg_pred\n",
    "# Prediction with \n",
    "pred_final = preds_with_ensemble()\n",
    "print('Test preds shape', pred_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af2a3bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:52.674506Z",
     "iopub.status.busy": "2024-03-16T18:10:52.674160Z",
     "iopub.status.idle": "2024-03-16T18:10:52.691003Z",
     "shell.execute_reply": "2024-03-16T18:10:52.690060Z"
    },
    "papermill": {
     "duration": 0.038729,
     "end_time": "2024-03-16T18:10:52.693015",
     "exception": false,
     "start_time": "2024-03-16T18:10:52.654286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissionn shape (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.073478</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.527459</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.298592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283        0.0887  0.073478  0.000345   0.527459   0.011426   \n",
       "\n",
       "   other_vote  \n",
       "0    0.298592  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub2 = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub2[TARGETS] = pred_final\n",
    "print('Submissionn shape',sub2.shape)\n",
    "display(sub2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf523547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:52.733003Z",
     "iopub.status.busy": "2024-03-16T18:10:52.732265Z",
     "iopub.status.idle": "2024-03-16T18:10:52.739061Z",
     "shell.execute_reply": "2024-03-16T18:10:52.738034Z"
    },
    "papermill": {
     "duration": 0.028697,
     "end_time": "2024-03-16T18:10:52.741109",
     "exception": false,
     "start_time": "2024-03-16T18:10:52.712412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub2.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29904ac",
   "metadata": {
    "papermill": {
     "duration": 0.018373,
     "end_time": "2024-03-16T18:10:52.778411",
     "exception": false,
     "start_time": "2024-03-16T18:10:52.760038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 3 @konstantinboyko   0.36\n",
    "https://www.kaggle.com/code/konstantinboyko/hms-full-validation-2-stage-s-train-infer/notebook?scriptVersionId=166580594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c27fcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:52.817048Z",
     "iopub.status.busy": "2024-03-16T18:10:52.816456Z",
     "iopub.status.idle": "2024-03-16T18:10:53.935834Z",
     "shell.execute_reply": "2024-03-16T18:10:53.934418Z"
    },
    "papermill": {
     "duration": 1.141214,
     "end_time": "2024-03-16T18:10:53.938145",
     "exception": false,
     "start_time": "2024-03-16T18:10:52.796931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 22.04.3 LTS\r\n",
      "BUILD_DATE=20240109-221321, CONTAINER_NAME=tf2-gpu/2-13+gpu\n",
      "PyTorch Version:2.0.0, CUDA is available:True, Version CUDA:11.8\n",
      "Device Capability:(7, 5), ['sm_37', 'sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n",
      "CuDNN Enabled:True, Version:8900\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.append(\"/kaggle/input/kaggle-kl-div\")\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\n",
    "print(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n",
    "    )\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6ce18e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:53.982400Z",
     "iopub.status.busy": "2024-03-16T18:10:53.981978Z",
     "iopub.status.idle": "2024-03-16T18:10:53.994119Z",
     "shell.execute_reply": "2024-03-16T18:10:53.992940Z"
    },
    "papermill": {
     "duration": 0.036689,
     "end_time": "2024-03-16T18:10:53.996307",
     "exception": false,
     "start_time": "2024-03-16T18:10:53.959618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter:True, kaggle:True, local:False\n",
      ".\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "class APP:\n",
    "    jupyter = \"ipykernel\" in globals()\n",
    "    if not jupyter:\n",
    "        try:\n",
    "            if \"IPython\" in globals().get(\"__doc__\", \"\"):\n",
    "                jupyter = True\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "\n",
    "    kaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\") != \"\"\n",
    "    local = os.environ.get(\"DOCKER_USING\", \"\") == \"LOCAL\"\n",
    "    date_time_start = dt.datetime.now()\n",
    "    dt_start_ymd_hms = date_time_start.strftime(\"%Y.%m.%d_%H-%M-%S\")\n",
    "\n",
    "    file_run_path = \"\"\n",
    "    if jupyter:\n",
    "        try:\n",
    "            file_run_path = Path(globals().get(\"__vsc_ipynb_file__\", \"\"))\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            file_run_path = Path(__file__)\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "\n",
    "    file_run_name = file_run_path.stem\n",
    "    path_app = file_run_path.parent\n",
    "    path_run = Path(os.getcwd())\n",
    "    path_out = (\n",
    "        Path(\"/kaggle/working\")\n",
    "        if kaggle\n",
    "        else file_run_path / f\"{file_run_name}_{dt_start_ymd_hms}\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"jupyter:{APP.jupyter}, kaggle:{APP.kaggle}, local:{APP.local}\")\n",
    "print(APP.file_run_path)\n",
    "print(APP.path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "426909a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.039227Z",
     "iopub.status.busy": "2024-03-16T18:10:54.038891Z",
     "iopub.status.idle": "2024-03-16T18:10:54.050843Z",
     "shell.execute_reply": "2024-03-16T18:10:54.049842Z"
    },
    "papermill": {
     "duration": 0.035334,
     "end_time": "2024-03-16T18:10:54.053103",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.017769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    VERSION = 93\n",
    "\n",
    "    model_name = \"resnet1d_gru\"\n",
    "\n",
    "    seed = 2024\n",
    "    batch_size = 32\n",
    "    num_workers = 0\n",
    "\n",
    "    fixed_kernel_size = 5\n",
    "    # kernels = [3, 5, 7, 9]\n",
    "    # linear_layer_features = 424\n",
    "    kernels = [3, 5, 7, 9, 11]\n",
    "    #linear_layer_features = 448  # Full Signal = 10_000\n",
    "    #linear_layer_features = 352  # Half Signal = 5_000\n",
    "    linear_layer_features = 304   # 1/5  Signal = 2_000\n",
    "\n",
    "    seq_length = 50  # Second's\n",
    "    sampling_rate = 200  # Hz\n",
    "    nsamples = seq_length * sampling_rate  #  \n",
    "    out_samples = nsamples // 5\n",
    "\n",
    "    # bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n",
    "    # rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n",
    "    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n",
    "    filter_order = 2\n",
    "    random_close_zone = 0.0  # 0.2\n",
    "        \n",
    "    target_cols = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]\n",
    "\n",
    "    # target_preds = [x + \"_pred\" for x in target_cols]\n",
    "    # label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    # num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "\n",
    "    map_features = [\n",
    "        (\"Fp1\", \"T3\"),\n",
    "        (\"T3\", \"O1\"),\n",
    "        (\"Fp1\", \"C3\"),\n",
    "        (\"C3\", \"O1\"),\n",
    "        (\"Fp2\", \"C4\"),\n",
    "        (\"C4\", \"O2\"),\n",
    "        (\"Fp2\", \"T4\"),\n",
    "        (\"T4\", \"O2\"),\n",
    "        #('Fz', 'Cz'), ('Cz', 'Pz'),        \n",
    "    ]\n",
    "\n",
    "    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz']\n",
    "        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']                    \n",
    "    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n",
    "    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n",
    "\n",
    "    # eeg_features = [row for row in feature_to_index]\n",
    "    # eeg_feat_size = len(eeg_features)\n",
    "    \n",
    "    n_map_features = len(map_features)\n",
    "    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n",
    "    target_size = len(target_cols)\n",
    "    \n",
    "    PATH = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n",
    "    test_eeg = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n",
    "    test_csv = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30ef82f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.094761Z",
     "iopub.status.busy": "2024-03-16T18:10:54.094196Z",
     "iopub.status.idle": "2024-03-16T18:10:54.099699Z",
     "shell.execute_reply": "2024-03-16T18:10:54.098723Z"
    },
    "papermill": {
     "duration": 0.028316,
     "end_time": "2024-03-16T18:10:54.101722",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.073406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "koef_1 = 1.0\n",
    "model_weights = [\n",
    "    {\n",
    "        'bandpass_filter':{'low':0.5, 'high':20, 'order':2}, \n",
    "        'file_data': \n",
    "        [\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_1_weight_oof/*_full.pth\"},\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/*_full.pth\"},\n",
    "            {'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/*_full.pth\"},\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_3_weight_oof/*_full.pth\"},\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1be2711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.142538Z",
     "iopub.status.busy": "2024-03-16T18:10:54.142166Z",
     "iopub.status.idle": "2024-03-16T18:10:54.158949Z",
     "shell.execute_reply": "2024-03-16T18:10:54.158155Z"
    },
    "papermill": {
     "duration": 0.03944,
     "end_time": "2024-03-16T18:10:54.160936",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.121496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=\"./test.log\"):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x  # quantized\n",
    "\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(\n",
    "    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n",
    "):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    #       ( ).\n",
    "    #   \n",
    "    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n",
    "    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n",
    "    y = y[0:-1:4]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feedb60d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.199846Z",
     "iopub.status.busy": "2024-03-16T18:10:54.199560Z",
     "iopub.status.idle": "2024-03-16T18:10:54.210920Z",
     "shell.execute_reply": "2024-03-16T18:10:54.210039Z"
    },
    "papermill": {
     "duration": 0.033012,
     "end_time": "2024-03-16T18:10:54.212869",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.179857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eeg_from_parquet(\n",
    "    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "            50  .     NaN\n",
    "       ( NaN).\n",
    "        :param parquet_path:    .\n",
    "        :param display:     .\n",
    "        :return data: np.array  (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "\n",
    "    #   50  \n",
    "    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n",
    "    rows = len(eeg)\n",
    "\n",
    "    #   ,   \n",
    "    offset = (rows - CFG.nsamples) // 2\n",
    "\n",
    "    #  50 ,       \n",
    "    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "\n",
    "    #   numpy\n",
    "\n",
    "    #       \n",
    "    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n",
    "\n",
    "    for index, feature in enumerate(CFG.eeg_features):\n",
    "        x = eeg[feature].values.astype(\"float32\")  #   float32\n",
    "\n",
    "        #      ,  NaN.\n",
    "        mean = np.nanmean(x)\n",
    "        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n",
    "\n",
    "        #   Nan\n",
    "        #    NaN       .\n",
    "        if nan_percentage < 1:  #     Nan,   \n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else:  #     Nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "\n",
    "        if display:\n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n",
    "            offset -= x.min()\n",
    "\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"EEG {name}\", size=16)\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5ef167c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.252054Z",
     "iopub.status.busy": "2024-03-16T18:10:54.251790Z",
     "iopub.status.idle": "2024-03-16T18:10:54.275733Z",
     "shell.execute_reply": "2024-03-16T18:10:54.274914Z"
    },
    "papermill": {
     "duration": 0.045801,
     "end_time": "2024-03-16T18:10:54.277589",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.231788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        eegs: Dict[int, np.ndarray],\n",
    "        mode: str = \"train\",\n",
    "        downsample: int = None,\n",
    "        bandpass_filter: Dict[str, Union[int, float]] = None,\n",
    "        rand_filter: Dict[str, Union[int, float]] = None,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        self.bandpass_filter = bandpass_filter\n",
    "        self.rand_filter = rand_filter\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        #     \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        #    \n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[:: self.downsample, :]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        #  ,    \n",
    "        X = np.zeros(\n",
    "            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n",
    "        )  # Size=(10000, 14)\n",
    "\n",
    "        row = self.df.iloc[index]  #  Pandas\n",
    "        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n",
    "        if CFG.nsamples != CFG.out_samples:\n",
    "            if self.mode != \"train\":\n",
    "                offset = (CFG.nsamples - CFG.out_samples) // 2\n",
    "            else:\n",
    "                #offset = random.randint(0, CFG.nsamples - CFG.out_samples)                \n",
    "                offset = ((CFG.nsamples - CFG.out_samples) * random.randint(0, 1000)) // 1000\n",
    "            data = data[offset:offset+CFG.out_samples,:]\n",
    "\n",
    "        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n",
    "            if self.mode == \"train\" and CFG.random_close_zone > 0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n",
    "                continue\n",
    "                \n",
    "            diff_feat = (\n",
    "                data[:, CFG.feature_to_index[feat_a]]\n",
    "                - data[:, CFG.feature_to_index[feat_b]]\n",
    "            )  # Size=(10000,)\n",
    "\n",
    "            if not self.bandpass_filter is None:\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "                    \n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, i] = diff_feat\n",
    "\n",
    "        n = CFG.n_map_features\n",
    "        if len(CFG.freq_channels) > 0:\n",
    "            for i in range(CFG.n_map_features):\n",
    "                diff_feat = X[:, i]\n",
    "                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n",
    "                    band_feat = butter_bandpass_filter(\n",
    "                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n",
    "                    )\n",
    "                    X[:, n] = band_feat\n",
    "                    n += 1\n",
    "\n",
    "        for spml_feat in CFG.simple_features:\n",
    "            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n",
    "            \n",
    "            if not self.bandpass_filter is None:\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, n] = feat_val\n",
    "            n += 1\n",
    "            \n",
    "        #     [-1024, 1024]\n",
    "        X = np.clip(X, -1024, 1024)\n",
    "\n",
    "        #  NaN      32\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        #       20 Hz.\n",
    "        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n",
    "\n",
    "        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n",
    "        if self.mode != \"test\":\n",
    "            y_prob = row[CFG.target_cols].values.astype(np.float32)\n",
    "\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bed24712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.316330Z",
     "iopub.status.busy": "2024-03-16T18:10:54.316033Z",
     "iopub.status.idle": "2024-03-16T18:10:54.342327Z",
     "shell.execute_reply": "2024-03-16T18:10:54.341511Z"
    },
    "papermill": {
     "duration": 0.048489,
     "end_time": "2024-03-16T18:10:54.344238",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.295749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        downsampling,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.PReLU()\n",
    "        # self.relu_2 = nn.PReLU()\n",
    "        self.relu_1 = nn.Hardswish()\n",
    "        self.relu_2 = nn.Hardswish()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels,\n",
    "        in_channels,\n",
    "        fixed_kernel_size,\n",
    "        num_classes,\n",
    "        linear_layer_features,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.planes,\n",
    "                kernel_size=(kernel_size),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                dilation=dilation,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.ReLU()\n",
    "        # self.relu_2 = nn.ReLU()\n",
    "        self.relu_1 = nn.SiLU()\n",
    "        self.relu_2 = nn.SiLU()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=self.planes,\n",
    "            out_channels=self.planes,\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.block = self._make_resnet_layer(\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=1,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            padding=fixed_kernel_size // 2,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_channels,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            # dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        blocks=9,\n",
    "        padding=0,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "            )\n",
    "            layers.append(\n",
    "                ResNet_1D_Block(\n",
    "                    in_channels=self.planes,\n",
    "                    out_channels=self.planes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    downsampling=downsampling,\n",
    "                    dilation=dilation,\n",
    "                    groups=groups,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  # <~~\n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "        return new_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        result = self.fc(new_out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a1fae0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.382694Z",
     "iopub.status.busy": "2024-03-16T18:10:54.382326Z",
     "iopub.status.idle": "2024-03-16T18:10:54.389454Z",
     "shell.execute_reply": "2024-03-16T18:10:54.388592Z"
    },
    "papermill": {
     "duration": 0.028506,
     "end_time": "2024-03-16T18:10:54.391413",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.362907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_function(test_loader, model, device):\n",
    "    model.eval()  # set model in evaluation mode\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    with tqdm(test_loader, unit=\"test_batch\", desc=\"Inference\") as tqdm_test_loader:\n",
    "        for step, batch in enumerate(tqdm_test_loader):\n",
    "            X = batch.pop(\"eeg\").to(device)  # send inputs to `device`\n",
    "            batch_size = X.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)  # forward propagation pass\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())  # save predictions\n",
    "\n",
    "    prediction_dict[\"predictions\"] = np.concatenate(\n",
    "        preds\n",
    "    )  # np.array() of shape (fold_size, target_cols)\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53a30ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.429441Z",
     "iopub.status.busy": "2024-03-16T18:10:54.429125Z",
     "iopub.status.idle": "2024-03-16T18:10:54.443270Z",
     "shell.execute_reply": "2024-03-16T18:10:54.442316Z"
    },
    "papermill": {
     "duration": 0.035435,
     "end_time": "2024-03-16T18:10:54.445500",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.410065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe shape is: (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id\n",
       "0          853520  3911565283        6885"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "print(f\"Test dataframe shape is: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "298d0494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:54.486963Z",
     "iopub.status.busy": "2024-03-16T18:10:54.486640Z",
     "iopub.status.idle": "2024-03-16T18:10:55.063905Z",
     "shell.execute_reply": "2024-03-16T18:10:55.062887Z"
    },
    "papermill": {
     "duration": 0.599533,
     "end_time": "2024-03-16T18:10:55.065922",
     "exception": false,
     "start_time": "2024-03-16T18:10:54.466389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 raw eeg features\n",
      "['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f959b303df04ad8a3aad48289f595e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_eeg_parquet_paths = glob(CFG.test_eeg + \"*.parquet\")\n",
    "test_eeg_df = pd.read_parquet(test_eeg_parquet_paths[0])\n",
    "test_eeg_features = test_eeg_df.columns\n",
    "print(f\"There are {len(test_eeg_features)} raw eeg features\")\n",
    "print(list(test_eeg_features))\n",
    "del test_eeg_df\n",
    "_ = gc.collect()\n",
    "\n",
    "# %%time\n",
    "all_eegs = {}\n",
    "eeg_ids = test_df.eeg_id.unique()\n",
    "for i, eeg_id in tqdm(enumerate(eeg_ids)):\n",
    "    # Save EEG to Python dictionary of numpy arrays\n",
    "    eeg_path = CFG.test_eeg + str(eeg_id) + \".parquet\"\n",
    "    data = eeg_from_parquet(eeg_path)\n",
    "    all_eegs[eeg_id] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68aa9ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:55.108835Z",
     "iopub.status.busy": "2024-03-16T18:10:55.108125Z",
     "iopub.status.idle": "2024-03-16T18:10:58.285076Z",
     "shell.execute_reply": "2024-03-16T18:10:58.284018Z"
    },
    "papermill": {
     "duration": 3.200723,
     "end_time": "2024-03-16T18:10:58.287409",
     "exception": false,
     "start_time": "2024-03-16T18:10:55.086686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2000, 8])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a230b712a9a44afabba9da4c746fd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9846a90731a4c9cbdc5b56f4afcdcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6bd2db208445bc99b2bf7c19a93b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2a8db71cdc47f392c037bbc7c4462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67064d410b4a49f5b9e820e9f0562ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "koef_sum = 0\n",
    "koef_count = 0\n",
    "predictions = []\n",
    "files = []\n",
    "    \n",
    "for model_block in model_weights:\n",
    "    test_dataset = EEGDataset(\n",
    "        df=test_df,\n",
    "        batch_size=CFG.batch_size,\n",
    "        mode=\"test\",\n",
    "        eegs=all_eegs,\n",
    "        bandpass_filter=model_block['bandpass_filter']\n",
    "    )\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        output = test_dataset[0]\n",
    "        X = output[\"eeg\"]\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "                \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    model = EEGNet(\n",
    "        kernels=CFG.kernels,\n",
    "        in_channels=CFG.in_channels,\n",
    "        fixed_kernel_size=CFG.fixed_kernel_size,\n",
    "        num_classes=CFG.target_size,\n",
    "        linear_layer_features=CFG.linear_layer_features,\n",
    "    )\n",
    "\n",
    "    for file_line in model_block['file_data']:\n",
    "        koef = file_line['koef']\n",
    "        for weight_model_file in glob(file_line['file_mask']):\n",
    "            files.append(weight_model_file)\n",
    "            checkpoint = torch.load(weight_model_file, map_location=device)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            model.to(device)\n",
    "            prediction_dict = inference_function(test_loader, model, device)\n",
    "            predict = prediction_dict[\"predictions\"]\n",
    "            predict *= koef\n",
    "            koef_sum += koef\n",
    "            koef_count += 1\n",
    "            predictions.append(predict)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "koef_sum /= koef_count\n",
    "predictions /= koef_sum\n",
    "predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7884b059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:58.334896Z",
     "iopub.status.busy": "2024-03-16T18:10:58.334559Z",
     "iopub.status.idle": "2024-03-16T18:10:58.341661Z",
     "shell.execute_reply": "2024-03-16T18:10:58.340668Z"
    },
    "papermill": {
     "duration": 0.032884,
     "end_time": "2024-03-16T18:10:58.343851",
     "exception": false,
     "start_time": "2024-03-16T18:10:58.310967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-1_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-4_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-2_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-0_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-3_full.pth']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(koef_count, koef_sum)\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d8d2913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:58.388617Z",
     "iopub.status.busy": "2024-03-16T18:10:58.387799Z",
     "iopub.status.idle": "2024-03-16T18:10:58.409188Z",
     "shell.execute_reply": "2024-03-16T18:10:58.408213Z"
    },
    "papermill": {
     "duration": 0.046254,
     "end_time": "2024-03-16T18:10:58.411404",
     "exception": false,
     "start_time": "2024-03-16T18:10:58.365150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>0.093476</td>\n",
       "      <td>0.089352</td>\n",
       "      <td>0.764305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.016862  0.026578  0.009426   0.093476   0.089352   \n",
       "\n",
       "   other_vote  \n",
       "0    0.764305  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub3 = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "sub3[CFG.target_cols] = predictions\n",
    "\n",
    "sub3.to_csv(f\"submission.csv\", index=False)\n",
    "print(f\"Submission shape: {sub3.shape}\")\n",
    "display(sub3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5c042da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:58.456169Z",
     "iopub.status.busy": "2024-03-16T18:10:58.455872Z",
     "iopub.status.idle": "2024-03-16T18:10:58.462554Z",
     "shell.execute_reply": "2024-03-16T18:10:58.461618Z"
    },
    "papermill": {
     "duration": 0.03136,
     "end_time": "2024-03-16T18:10:58.465181",
     "exception": false,
     "start_time": "2024-03-16T18:10:58.433821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub3.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15bcbb9",
   "metadata": {
    "papermill": {
     "duration": 0.021369,
     "end_time": "2024-03-16T18:10:58.509831",
     "exception": false,
     "start_time": "2024-03-16T18:10:58.488462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a4614c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:58.554808Z",
     "iopub.status.busy": "2024-03-16T18:10:58.553900Z",
     "iopub.status.idle": "2024-03-16T18:10:58.577384Z",
     "shell.execute_reply": "2024-03-16T18:10:58.576393Z"
    },
    "papermill": {
     "duration": 0.048435,
     "end_time": "2024-03-16T18:10:58.579692",
     "exception": false,
     "start_time": "2024-03-16T18:10:58.531257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>0.00353</td>\n",
       "      <td>0.330814</td>\n",
       "      <td>0.037198</td>\n",
       "      <td>0.513825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.046655  0.067978   0.00353   0.330814   0.037198   \n",
       "\n",
       "   other_vote  \n",
       "0    0.513825  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_final = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    sub1[f'{labels[i]}_vote'] = test_preds[:, i]\n",
    "sub2[TARGETS] = pred_final\n",
    "sub3[CFG.target_cols] = predictions\n",
    "    \n",
    "for label in labels:\n",
    "    sub_final[f'{label}_vote'] = (sub1[f'{label}_vote'] + sub2[f'{label}_vote'] + sub3[f'{label}_vote']) / 3.0 \n",
    "\n",
    "sub_final.to_csv(f\"submission.csv\", index=False)\n",
    "print(f\"Submission shape: {sub_final.shape}\")\n",
    "display(sub_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "630b7c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T18:10:58.627012Z",
     "iopub.status.busy": "2024-03-16T18:10:58.626697Z",
     "iopub.status.idle": "2024-03-16T18:10:58.633557Z",
     "shell.execute_reply": "2024-03-16T18:10:58.632587Z"
    },
    "papermill": {
     "duration": 0.03227,
     "end_time": "2024-03-16T18:10:58.635876",
     "exception": false,
     "start_time": "2024-03-16T18:10:58.603606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub_final.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4317718,
     "sourceId": 7465251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4378712,
     "sourceId": 7517324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4407194,
     "sourceId": 7570342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4382744,
     "sourceId": 7752462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4550181,
     "sourceId": 7776446,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4417235,
     "sourceId": 7818976,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4581021,
     "sourceId": 7819029,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 160674831,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 160700706,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 161586765,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.85596,
   "end_time": "2024-03-16T18:11:01.764137",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-16T18:09:10.908177",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "000aadc14b5f41dd97db861e2db570ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "00c5c435c9394cc0a3b90e7f91076dcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_098dd5e57bf744b487ca3ae0fb66bdc9",
       "placeholder": "",
       "style": "IPY_MODEL_41ca4ca3cf5245e0a6c4dce12e555f72",
       "value": "Inference: 100%"
      }
     },
     "03d4a9917e1b49ffad10d874a0fec836": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a09c2ccafddd4fae9d813525205fdcb6",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_50cfb793f6f14f18abcda16c10a30c97",
       "value": 1.0
      }
     },
     "098dd5e57bf744b487ca3ae0fb66bdc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a230b712a9a44afabba9da4c746fd0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00c5c435c9394cc0a3b90e7f91076dcc",
        "IPY_MODEL_2a0174ea1814446888136b283b227213",
        "IPY_MODEL_266d7c7bd0ce4e85828eec27e34b9636"
       ],
       "layout": "IPY_MODEL_0d822a982a374f0a82aeea1441683df1"
      }
     },
     "0a9e2c3ff7a447318917ada7e6096c4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b27bd8dc17f406ba8be2656b6540814": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d822a982a374f0a82aeea1441683df1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ea66ffd778941d7b57cfa8fc0e35823": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f90396eb65114f92839bb41025c301f9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ec6e3d3725f44a11a525b6c249aa549c",
       "value": 1.0
      }
     },
     "15fdcad7d15b4b9d83b16a780da7a4c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "20f8e4c5aaee477fbe566f304362fd45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "266d7c7bd0ce4e85828eec27e34b9636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9955d94efd642139ec9872604578376",
       "placeholder": "",
       "style": "IPY_MODEL_421bdefe2d6041b4803f2faba182e808",
       "value": " 1/1 [00:00&lt;00:00,  2.47test_batch/s]"
      }
     },
     "2a0174ea1814446888136b283b227213": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ea49036b96240a8b843155136d77f87",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a9e2c3ff7a447318917ada7e6096c4a",
       "value": 1.0
      }
     },
     "3482d61843f249919f5862a1e4cf955a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "378c1a77acfb424f88b8e4ff84c00b75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3eecd4b42fa048198f8af09aa8054c78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "41ca4ca3cf5245e0a6c4dce12e555f72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "421bdefe2d6041b4803f2faba182e808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "463ada45254d4e19b68a102ac714318f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfe32089f82648ac89f816184ce10b22",
       "placeholder": "",
       "style": "IPY_MODEL_8861bf4ef4b84ea6af9348e08a917d38",
       "value": "Inference: 100%"
      }
     },
     "4b2a8db71cdc47f392c037bbc7c4462a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e5fa232ee3e24c73ab10cc5f3c3c2568",
        "IPY_MODEL_0ea66ffd778941d7b57cfa8fc0e35823",
        "IPY_MODEL_95a825edf54247fa91493a542654a956"
       ],
       "layout": "IPY_MODEL_83c94a8f76bb4f7cbb42dcef67c57f97"
      }
     },
     "4ea49036b96240a8b843155136d77f87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fe9609ad6e84285ad06a50471fbcbb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50cfb793f6f14f18abcda16c10a30c97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "52aa4fe25b8c4296a4d1c35bedcec322": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5a1ed165903e4e8d916cb2cbf078e13a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7d5e56e878e947ebab18949d9e509936",
       "placeholder": "",
       "style": "IPY_MODEL_78e16e7498564f29b04bcc24147ba7de",
       "value": ""
      }
     },
     "608c227d646a4ac4b9c55e6338760e5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f72e7023c846434b958f9e3afbf95c36",
       "placeholder": "",
       "style": "IPY_MODEL_a0057484c84341d1a819db629c04ecb4",
       "value": " 1/1 [00:00&lt;00:00, 23.35test_batch/s]"
      }
     },
     "67064d410b4a49f5b9e820e9f0562ad7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f879324bf02341c9af2df6452fbafb92",
        "IPY_MODEL_e391a5e1a73e4eedb53ecd7125826099",
        "IPY_MODEL_9f76946bbbb2465c9e484ccc9c1ca820"
       ],
       "layout": "IPY_MODEL_378c1a77acfb424f88b8e4ff84c00b75"
      }
     },
     "67e367f20e6e47f5af4e0a3f7ff2f658": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "6b07497e319d48d491df222a9d7b054b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f959b303df04ad8a3aad48289f595e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a1ed165903e4e8d916cb2cbf078e13a",
        "IPY_MODEL_a5b3b84007404925a82271fa1ef567fe",
        "IPY_MODEL_f39ee415c1864f78beed2d4e905a019c"
       ],
       "layout": "IPY_MODEL_c9d7a2e463f74a129278f9817c95c353"
      }
     },
     "7156db6d30c740f8a52057dc08a4041e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72264e0fc6b840d2914b2f04aff0dd9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78e16e7498564f29b04bcc24147ba7de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7d5e56e878e947ebab18949d9e509936": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83c94a8f76bb4f7cbb42dcef67c57f97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "849635e4f148424cad1e8ff5c0d1e0eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8861bf4ef4b84ea6af9348e08a917d38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "92b85d57ea54400281906ff622af7511": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_acd4f9a880094af998d2eecd2ef3c087",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e49c2007558c41c7b642607511026135",
       "value": 1.0
      }
     },
     "9372e2734c034462a4a057826ebb540e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20f8e4c5aaee477fbe566f304362fd45",
       "placeholder": "",
       "style": "IPY_MODEL_52aa4fe25b8c4296a4d1c35bedcec322",
       "value": "Inference: 100%"
      }
     },
     "93e75402ea164a44a305e3d999ab008d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "95a825edf54247fa91493a542654a956": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c528061a24aa44b9a87006cd71e90ca3",
       "placeholder": "",
       "style": "IPY_MODEL_d76c99a3224645f184521d227bc01a75",
       "value": " 1/1 [00:00&lt;00:00, 24.77test_batch/s]"
      }
     },
     "9f76946bbbb2465c9e484ccc9c1ca820": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c558aa336e2d40e6945c7bb8c25e5e52",
       "placeholder": "",
       "style": "IPY_MODEL_000aadc14b5f41dd97db861e2db570ee",
       "value": " 1/1 [00:00&lt;00:00, 21.70test_batch/s]"
      }
     },
     "a0057484c84341d1a819db629c04ecb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a09c2ccafddd4fae9d813525205fdcb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a254b06d44c741b6924d10491a76e120": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a5b3b84007404925a82271fa1ef567fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67e367f20e6e47f5af4e0a3f7ff2f658",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7d1b33a910d44caaa0711079d74398d",
       "value": 1.0
      }
     },
     "ac30608b7d5f4c878e6d7c9eb414be05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acd4f9a880094af998d2eecd2ef3c087": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b54c7699148143078a6d67710ead42bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7156db6d30c740f8a52057dc08a4041e",
       "placeholder": "",
       "style": "IPY_MODEL_3eecd4b42fa048198f8af09aa8054c78",
       "value": " 1/1 [00:00&lt;00:00, 19.46test_batch/s]"
      }
     },
     "c528061a24aa44b9a87006cd71e90ca3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c558aa336e2d40e6945c7bb8c25e5e52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c9d7a2e463f74a129278f9817c95c353": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb6bd2db208445bc99b2bf7c19a93b02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_463ada45254d4e19b68a102ac714318f",
        "IPY_MODEL_92b85d57ea54400281906ff622af7511",
        "IPY_MODEL_b54c7699148143078a6d67710ead42bb"
       ],
       "layout": "IPY_MODEL_72264e0fc6b840d2914b2f04aff0dd9b"
      }
     },
     "d76c99a3224645f184521d227bc01a75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d9846a90731a4c9cbdc5b56f4afcdcc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9372e2734c034462a4a057826ebb540e",
        "IPY_MODEL_03d4a9917e1b49ffad10d874a0fec836",
        "IPY_MODEL_608c227d646a4ac4b9c55e6338760e5c"
       ],
       "layout": "IPY_MODEL_ac30608b7d5f4c878e6d7c9eb414be05"
      }
     },
     "dfe32089f82648ac89f816184ce10b22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e391a5e1a73e4eedb53ecd7125826099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b27bd8dc17f406ba8be2656b6540814",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_15fdcad7d15b4b9d83b16a780da7a4c3",
       "value": 1.0
      }
     },
     "e49c2007558c41c7b642607511026135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e5fa232ee3e24c73ab10cc5f3c3c2568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fe9609ad6e84285ad06a50471fbcbb9",
       "placeholder": "",
       "style": "IPY_MODEL_849635e4f148424cad1e8ff5c0d1e0eb",
       "value": "Inference: 100%"
      }
     },
     "e9955d94efd642139ec9872604578376": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec6e3d3725f44a11a525b6c249aa549c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f39ee415c1864f78beed2d4e905a019c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3482d61843f249919f5862a1e4cf955a",
       "placeholder": "",
       "style": "IPY_MODEL_93e75402ea164a44a305e3d999ab008d",
       "value": " 1/? [00:00&lt;00:00, 36.04it/s]"
      }
     },
     "f72e7023c846434b958f9e3afbf95c36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7d1b33a910d44caaa0711079d74398d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f879324bf02341c9af2df6452fbafb92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b07497e319d48d491df222a9d7b054b",
       "placeholder": "",
       "style": "IPY_MODEL_a254b06d44c741b6924d10491a76e120",
       "value": "Inference: 100%"
      }
     },
     "f90396eb65114f92839bb41025c301f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
